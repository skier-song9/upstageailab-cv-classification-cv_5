{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkH9T_86lDSS"
      },
      "source": [
        "## 1. Prepare Environments\n",
        "\n",
        "* ë°ì´í„° í´ë”ì˜ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "* í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ import í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "### í•œêµ­ì–´ ì„¤ì¹˜ apt-get installì—ì„œ Error ë°œìƒ ì‹œ, 'sudo' ëª…ë ¹ì–´ ì¶”ê°€í•´ì„œ root ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰.\n",
        "# !apt-get install fonts-nanum*\n",
        "# !fc-cache -fv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# utils\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import copy\n",
        "import time\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows',None) # ë˜ëŠ” ìˆ«ì ì§€ì •\n",
        "pd.set_option('display.max_columns',None)\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "fe = fm.FontEntry(\n",
        "    fname='/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf', # ttf íŒŒì¼ ì €ì¥ ê²½ë¡œ\n",
        "    name='NanumBarunGothic' # ë³„ì¹­\n",
        ")\n",
        "fm.fontManager.ttflist.insert(0,fe)\n",
        "plt.rcParams.update({'font.family' : 'NanumBarunGothic'}) # í•œê¸€ íŒ¨ì¹˜\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rcParams['axes.unicode_minus'] =False # ìŒìˆ˜ ë¶€í˜¸ ì•ˆ ê¹¨ì§€ê²Œ\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "import torch.nn.init as init\n",
        "\n",
        "# Image Augmentation\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from augraphy import *\n",
        "\n",
        "# train dataset augmentation\n",
        "import cv2\n",
        "import itertools\n",
        "\n",
        "### random seed ê³ ì • í•¨ìˆ˜\n",
        "def set_seed(seed: int = 42):\n",
        "    \"\"\"ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "    :param int seed: ê³ ì •í•  ì‹œë“œ ê°’, defaults to 42\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    try:\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # ë©€í‹° GPUìš©\n",
        "        \n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except ImportError:\n",
        "        pass  # torchê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ë¬´ì‹œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í˜„ì¬ jupyter notebookì˜ ì‹¤í–‰ ê²½ë¡œ: /data/ephemeral/home/upstageailab-cv-classification-cv_5/codes/practice\n"
          ]
        }
      ],
      "source": [
        "print(\"í˜„ì¬ jupyter notebookì˜ ì‹¤í–‰ ê²½ë¡œ:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['resnet10t.c3_in1k',\n",
              " 'resnet14t.c3_in1k',\n",
              " 'resnet18.a1_in1k',\n",
              " 'resnet18.a2_in1k',\n",
              " 'resnet18.a3_in1k',\n",
              " 'resnet18.fb_ssl_yfcc100m_ft_in1k',\n",
              " 'resnet18.fb_swsl_ig1b_ft_in1k',\n",
              " 'resnet18.gluon_in1k',\n",
              " 'resnet18.tv_in1k',\n",
              " 'resnet18d.ra2_in1k',\n",
              " 'resnet26.bt_in1k',\n",
              " 'resnet26d.bt_in1k',\n",
              " 'resnet26t.ra2_in1k',\n",
              " 'resnet32ts.ra2_in1k',\n",
              " 'resnet33ts.ra2_in1k',\n",
              " 'resnet34.a1_in1k',\n",
              " 'resnet34.a2_in1k',\n",
              " 'resnet34.a3_in1k',\n",
              " 'resnet34.bt_in1k',\n",
              " 'resnet34.gluon_in1k',\n",
              " 'resnet34.tv_in1k',\n",
              " 'resnet34d.ra2_in1k',\n",
              " 'resnet50.a1_in1k',\n",
              " 'resnet50.a1h_in1k',\n",
              " 'resnet50.a2_in1k',\n",
              " 'resnet50.a3_in1k',\n",
              " 'resnet50.am_in1k',\n",
              " 'resnet50.b1k_in1k',\n",
              " 'resnet50.b2k_in1k',\n",
              " 'resnet50.bt_in1k',\n",
              " 'resnet50.c1_in1k',\n",
              " 'resnet50.c2_in1k',\n",
              " 'resnet50.d_in1k',\n",
              " 'resnet50.fb_ssl_yfcc100m_ft_in1k',\n",
              " 'resnet50.fb_swsl_ig1b_ft_in1k',\n",
              " 'resnet50.gluon_in1k',\n",
              " 'resnet50.ra_in1k',\n",
              " 'resnet50.ram_in1k',\n",
              " 'resnet50.tv2_in1k',\n",
              " 'resnet50.tv_in1k',\n",
              " 'resnet50_gn.a1h_in1k',\n",
              " 'resnet50c.gluon_in1k',\n",
              " 'resnet50d.a1_in1k',\n",
              " 'resnet50d.a2_in1k',\n",
              " 'resnet50d.a3_in1k',\n",
              " 'resnet50d.gluon_in1k',\n",
              " 'resnet50d.ra2_in1k',\n",
              " 'resnet50s.gluon_in1k',\n",
              " 'resnet51q.ra2_in1k',\n",
              " 'resnet61q.ra2_in1k',\n",
              " 'resnet101.a1_in1k',\n",
              " 'resnet101.a1h_in1k',\n",
              " 'resnet101.a2_in1k',\n",
              " 'resnet101.a3_in1k',\n",
              " 'resnet101.gluon_in1k',\n",
              " 'resnet101.tv2_in1k',\n",
              " 'resnet101.tv_in1k',\n",
              " 'resnet101c.gluon_in1k',\n",
              " 'resnet101d.gluon_in1k',\n",
              " 'resnet101d.ra2_in1k',\n",
              " 'resnet101s.gluon_in1k',\n",
              " 'resnet152.a1_in1k',\n",
              " 'resnet152.a1h_in1k',\n",
              " 'resnet152.a2_in1k',\n",
              " 'resnet152.a3_in1k',\n",
              " 'resnet152.gluon_in1k',\n",
              " 'resnet152.tv2_in1k',\n",
              " 'resnet152.tv_in1k',\n",
              " 'resnet152c.gluon_in1k',\n",
              " 'resnet152d.gluon_in1k',\n",
              " 'resnet152d.ra2_in1k',\n",
              " 'resnet152s.gluon_in1k',\n",
              " 'resnet200d.ra2_in1k',\n",
              " 'resnetaa50.a1h_in1k',\n",
              " 'resnetaa50d.d_in12k',\n",
              " 'resnetaa50d.sw_in12k',\n",
              " 'resnetaa50d.sw_in12k_ft_in1k',\n",
              " 'resnetaa101d.sw_in12k',\n",
              " 'resnetaa101d.sw_in12k_ft_in1k',\n",
              " 'resnetblur50.bt_in1k',\n",
              " 'resnetrs50.tf_in1k',\n",
              " 'resnetrs101.tf_in1k',\n",
              " 'resnetrs152.tf_in1k',\n",
              " 'resnetrs200.tf_in1k',\n",
              " 'resnetrs270.tf_in1k',\n",
              " 'resnetrs350.tf_in1k',\n",
              " 'resnetrs420.tf_in1k',\n",
              " 'resnetv2_50.a1h_in1k',\n",
              " 'resnetv2_50d_evos.ah_in1k',\n",
              " 'resnetv2_50d_gn.ah_in1k',\n",
              " 'resnetv2_50x1_bit.goog_distilled_in1k',\n",
              " 'resnetv2_50x1_bit.goog_in21k',\n",
              " 'resnetv2_50x1_bit.goog_in21k_ft_in1k',\n",
              " 'resnetv2_50x3_bit.goog_in21k',\n",
              " 'resnetv2_50x3_bit.goog_in21k_ft_in1k',\n",
              " 'resnetv2_101.a1h_in1k',\n",
              " 'resnetv2_101x1_bit.goog_in21k',\n",
              " 'resnetv2_101x1_bit.goog_in21k_ft_in1k',\n",
              " 'resnetv2_101x3_bit.goog_in21k',\n",
              " 'resnetv2_101x3_bit.goog_in21k_ft_in1k',\n",
              " 'resnetv2_152x2_bit.goog_in21k',\n",
              " 'resnetv2_152x2_bit.goog_in21k_ft_in1k',\n",
              " 'resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k',\n",
              " 'resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384',\n",
              " 'resnetv2_152x4_bit.goog_in21k',\n",
              " 'resnetv2_152x4_bit.goog_in21k_ft_in1k']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timm.list_models(filter=\"resnet*\", pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš™ï¸ Data Directory Path: /data/ephemeral/home/upstageailab-cv-classification-cv_5/data\n",
            "âš™ï¸ Device : cuda\n",
            "âŒš ì‹¤í—˜ ì‹œê°„: 2507022317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mahyeon1\u001b[0m (\u001b[33mahyeon1-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¢ run name: 2507022317-resnet50.a1_in1k-opt_AdamW-img224-aug_0\n"
          ]
        }
      ],
      "source": [
        "project_root = '/data/ephemeral/home/upstageailab-cv-classification-cv_5'\n",
        "data_dir = os.path.join(project_root, 'data')\n",
        "print(\"âš™ï¸ Data Directory Path:\", data_dir)\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(\"âš™ï¸ Device :\",device)\n",
        "\n",
        "from zoneinfo import ZoneInfo\n",
        "from datetime import datetime\n",
        "CURRENT_TIME = datetime.now(ZoneInfo(\"Asia/Seoul\")).strftime(\"%y%m%d%H%M\")\n",
        "print(f\"âŒš ì‹¤í—˜ ì‹œê°„: {CURRENT_TIME}\")\n",
        "\n",
        "CFG = {\n",
        "    'model_name': 'resnet50.a1_in1k', # timm model name\n",
        "    'pretrained': True, # timm pretrained ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€\n",
        "    'fine_tuning': \"full\", # fine-tuning ë°©ë²•ë¡ \n",
        "    # full : pretrained=True, pretrainedê°€ì¤‘ì¹˜ë¥¼ ì „ë¶€ ì¬í•™ìŠµì‹œí‚¨ë‹¤. \n",
        "    # head : pretrained=True, model backbone ë¶€ë¶„ì€ freezeí•˜ê³  head ë¶€ë¶„ì„ ì¬í•™ìŠµì‹œí‚¨ë‹¤.\n",
        "    # custom : pretrained=True, backboneì—ì„œë„ ì¼ë¶€ë¶„ì„ ì¬í•™ìŠµì‹œí‚¨ë‹¤.\n",
        "    # scratch : pretrained=False, ëª¨ë¸ êµ¬ì¡°ë§Œ ì‚¬ìš©í•˜ê³  ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ ì²˜ìŒë¶€í„° í•™ìŠµì‹œí‚¨ë‹¤.\n",
        "    # Loss Function\n",
        "    'criterion': 'CrossEntropyLoss',\n",
        "    # optimizer name: SGD, RMSprop, Momentum, NAG, Adam, AdamW, NAdam, RAdam, Adafactor\n",
        "    # reference : https://www.notion.so/skier-song9/Pytorch-9cfee0520ed6468a94b024ea35e48018?source=copy_link#217c8d3f60f58044beeac55596433dc6\n",
        "    'optimizer_name': 'AdamW', \n",
        "    'lr': 1e-2, # learning rate\n",
        "    'weight_decay': 1e-4, # weight decay ratio\n",
        "    # scheduler_name : StepLR, ExponentialLR, CosineAnnealingLR, OneCycleLR, ReduceLROnPlateau\n",
        "    # reference : https://www.notion.so/skier-song9/Pytorch-9cfee0520ed6468a94b024ea35e48018?source=copy_link#1d2c8d3f60f58026b71ad399ead029a9\n",
        "    'scheduler_name': 'OneCycleLR',\n",
        "    \n",
        "    # ê¸°íƒ€ ë³€ìˆ˜ë“¤\n",
        "    'random_seed': 256, \n",
        "    'n_folds': 5, # validation set, cross-validation ì‹œ foldì˜ ê°œìˆ˜\n",
        "    'val_split_ratio': 0.15, # train-val split ë¹„ìœ¨\n",
        "    'stratify': True, # validation set ë¶„í•  ì‹œ stratify ì „ëµ ì‚¬ìš© ì—¬ë¶€\n",
        "    'image_size': 224, # ë§Œì•½ multi-scale train/test ì‹œ Noneìœ¼ë¡œ ì„¤ì •\n",
        "\n",
        "    # normalization mean, std\n",
        "    # full file tuning ì‹œ 0.5ê°€ ìœ ë¦¬\n",
        "    # pre-trained ëª¨ë¸ ì‚¬ìš© ì‹œ pre-trained ëª¨ë¸ì˜ mean, stdë¥¼ ì‚¬ìš©\n",
        "    'norm_mean': [0.5, 0.5, 0.5],\n",
        "    'norm_std': [0.5, 0.5, 0.5],\n",
        "\n",
        "    # ì ìš©í•˜ëŠ” ê¸°ë²•ë“¤ ëª…ì‹œ\n",
        "    'augmentation': {},\n",
        "\n",
        "    # ëª¨ë¸ì— ëŒ€í•œ hyperparameters\n",
        "    'model_layer': {}, # model layerì˜ filter size, activation function, pooling layer ë“± ë³€ê²½ ì‹œ ì‘ì„±\n",
        "    'dropout': 0.3, # model layerì—ì„œ dropout ë¹„ìœ¨ ë³€ê²½ ì‹œ ì‘ì„±\n",
        "    'timm_activation': \"ReLU\",\n",
        "    'activation': \"SELU\", # ReLU, LeakyReLU, ELU, SELU, GELU, Tanh, PReLU, SiLU\n",
        "\n",
        "    # í•™ìŠµ ì‹œ hyperparameters\n",
        "    'epochs': 10000, # max epoch\n",
        "    'patience': 50, # early stopping patience\n",
        "    'batch_size': 64,\n",
        "\n",
        "    # device\n",
        "    'device': device # device name\n",
        "}\n",
        "if CFG['patience'] < 5:\n",
        "    raise ValueError(\"Ealry stopping patience must be larger than 5!\")\n",
        "\n",
        "# wandb setting\n",
        "import wandb\n",
        "wandb.login()\n",
        "WB = False # wandb ê¸°ë¡í•  ê±°ë©´ True, ì•„ë‹ˆë©´ False.\n",
        "project_name = \"upstage-img-clf\"\n",
        "# def get_runs(project_name):\n",
        "#     # wandb projectì˜ runsë“¤ì„ ê°€ì ¸ì˜´\n",
        "#     return wandb.Api().runs(path=project_name, order=\"-created_at\")\n",
        "# def get_latest_run(project_name):\n",
        "#     runs = get_runs(project_name) # wandb projectì˜ runsë“¤ì„ ê°€ì ¸ì˜´\n",
        "#     if not runs: # ìµœì´ˆ runsì—ëŠ” project_name-001 ë¡œ ì´ë¦„ì„ ë§Œë“ ë‹¤.\n",
        "#         return f\"{CFG['model_name']}-opt_{CFG['optimizer_name']}-img{CFG['image_size']}-aug_{len(CFG['augmentation'])}-{CURRENT_TIME}-0000\"\n",
        "#     return runs[0].name # ê°€ì¥ ìµœê·¼ì˜ runs ì´ë¦„ì„ ê°€ì ¸ì˜¨ë‹¤.\n",
        "# def auto_increment_run_suffix(name: str, pad=4):\n",
        "#     suffix = name.split(\"-\")[-1]\n",
        "#     next_suffix = str(int(suffix) + 1).zfill(pad) # 2 > 0002\n",
        "#     return name.replace(suffix, next_suffix)\n",
        "# recent_run_name = get_latest_run(project_name)\n",
        "# next_run_name = auto_increment_run_suffix(recent_run_name) # ê°€ì¥ ìµœê·¼ runsì˜ ìˆ«ìë¥¼ 1 ì˜¬ë¦°ë‹¤.\n",
        "next_run_name = f\"{CURRENT_TIME}-{CFG['model_name']}-opt_{CFG['optimizer_name']}-img{CFG['image_size']}-aug_{len(CFG['augmentation'])}\"\n",
        "print(f\"ğŸ“¢ run name: {next_run_name}\")\n",
        "run = None\n",
        "if WB:\n",
        "    run = wandb.init(\n",
        "        project=project_name,\n",
        "        name=next_run_name,\n",
        "        config=CFG\n",
        "    )\n",
        "    pass\n",
        "\n",
        "# transform dictionary into namespace\n",
        "from types import SimpleNamespace\n",
        "CFG = SimpleNamespace(**CFG)\n",
        "\n",
        "# set random seed\n",
        "set_seed(CFG.random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# download data\n",
        "# os.chdir(project_root)\n",
        "# !wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000356/data/data.tar.gz\n",
        "# !tar -zxvf data.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXa_FPM73R9f"
      },
      "source": [
        "## 2. Import Library & Define Functions\n",
        "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Hyl8oAy6TZAu"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "class ImageDataset(Dataset):\n",
        "    # def __init__(self, csv, path, transform=None):\n",
        "    def __init__(self, df:pd.DataFrame, path, transform=None):\n",
        "        \"\"\"\n",
        "        :param pd.DataFrame df: train-valì„ ìœ„í•´ì„œëŠ” pandas.Dataframeìœ¼ë¡œ ë°›ì•„ì•¼ í•¨.\n",
        "        :param str path: ì´ë¯¸ì§€ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
        "        :param _type_ transform: ì´ë¯¸ì§€ ë³€í˜•, defaults to None\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.path = path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name, target = self.df.iloc[idx]\n",
        "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)['image']\n",
        "        return img, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "class EarlyStopping:\n",
        "\tdef __init__(self, patience=5, min_delta=1e-6, restore_best_weights=True):\n",
        "\t\tself.patience = patience\n",
        "\t\tself.min_delta = min_delta\n",
        "\t\tself.restore_best_weights = restore_best_weights\n",
        "\t\tself.best_model_state_dict = None\n",
        "\t\tself.best_loss = None\n",
        "\t\tself.counter = 0\n",
        "\t\tself.status = \"\"\n",
        "\t\n",
        "\tdef __call__(self, model, val_loss):\n",
        "\t\tif self.best_loss is None:\n",
        "\t\t\t#í˜„ì¬ì˜ ëª¨ë¸ë¡œ self.best_loss, self.best_model_state_dict ì—…ë°ì´íŠ¸\n",
        "\t\t\tself.best_loss = val_loss\n",
        "\t\t\tself.best_model_state_dict = copy.deepcopy(model.state_dict())\n",
        "\t\telif val_loss < self.best_loss - self.min_delta:\n",
        "\t\t\t#val_lossê°€ best_lossë³´ë‹¤ ì¢‹ì„ ë•Œ > self.best_lossì™€ self.best_model ì—…ë°ì´íŠ¸\n",
        "\t\t\tself.best_model_state_dict = copy.deepcopy(model.state_dict())\n",
        "\t\t\tself.best_loss = val_loss\n",
        "\t\t\tself.counter = 0\n",
        "\t\t\tself.status = f\"Improvement found, counter reset to {self.counter}\"\n",
        "\t\telse:\n",
        "\t\t\t#val_lossê°€ ë” ì•ˆ ì¢‹ì„ ë•Œ > patience ì¦ê°€í•˜ê³  early stop ì—¬ë¶€ í™•ì¸\n",
        "\t\t\tself.counter += 1\n",
        "\t\t\tself.status = f\"No improvement in the last {self.counter} epochs\"\n",
        "\t\t\tif self.counter >= self.patience: # ealy stop\n",
        "\t\t\t\tself.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
        "\t\t\t\tif self.restore_best_weights and self.best_model_state_dict is not None:\n",
        "\t\t\t\t\tmodel.load_state_dict(self.best_model_state_dict)\n",
        "\t\t\t\t\treturn True\n",
        "\t\treturn False # end with no early stop\n",
        "\t\n",
        "\tdef restore_best(self, model):\n",
        "\t\tif self.best_loss is not None and self.best_model_state_dict is not None:\n",
        "\t\t\tprint(f\"Restore model_state_dict of which best_loss: {self.best_loss:.6f}\")\n",
        "\t\t\tmodel.load_state_dict(self.best_model_state_dict)\n",
        "\t\t\treturn True\n",
        "\t\treturn False\n",
        "\n",
        "class TrainModule():\n",
        "\tdef __init__(self, model: torch.nn.Module, criterion, optimizer, scheduler, train_loader, valid_loader, cfg: SimpleNamespace, verbose:int =50, run=None):\n",
        "\t\t'''\n",
        "\t\tmodel, criterion, scheduler, train_loader, valid_loader ë¯¸ë¦¬ ì •ì˜í•´ì„œ ì „ë‹¬\n",
        "\t\tcfg : es_patience, epochs ë“±ì— ëŒ€í•œ hyperparametersë¥¼ namespace ê°ì²´ë¡œ ì…ë ¥\n",
        "\t\t'''\n",
        "\t\trequired_attrs = ['scheduler_name','patience', 'epochs']\n",
        "\t\tfor attr in required_attrs:\n",
        "\t\t\tassert hasattr(cfg, attr), f\"AttributeError: There's no '{attr}' attribute in cfg.\"\n",
        "\t\tassert verbose > 1 and verbose < cfg.epochs, f\"Logging frequency({verbose}) MUST BE smaller than EPOCHS({cfg.epochs}) and positive value.\"\n",
        "\t\t\n",
        "\t\tself.model = model\n",
        "\t\tself.criterion = criterion\n",
        "\t\tself.optimizer = optimizer\n",
        "\t\tself.scheduler = scheduler\n",
        "\t\tself.train_loader = train_loader\n",
        "\t\tself.valid_loader = valid_loader\n",
        "\t\tself.cfg = cfg\n",
        "\t\tif getattr(cfg, \"device\", False):\n",
        "\t\t\tself.model.to(self.cfg.device)\n",
        "\t\telse:\n",
        "\t\t\tself.cfg.device = 'cpu'\n",
        "\t\tself.es = EarlyStopping(patience=self.cfg.patience)\n",
        "\t\t### list for plot\n",
        "\t\tself.train_losses_for_plot, self.val_losses_for_plot = [], []\n",
        "\t\tself.train_acc_for_plot, self.val_acc_for_plot = [], [] # classification\n",
        "\t\tself.train_f1_for_plot, self.val_f1_for_plot = [], [] # classification\n",
        "\t\t# logging frequency\n",
        "\t\tself.verbose = verbose\n",
        "\t\t# wandb run object\n",
        "\t\tself.run = run\n",
        "\t\t\n",
        "\tdef training_step(self):\n",
        "\t\t# set train mode\n",
        "\t\tself.model.train()\n",
        "\t\trunning_loss = 0.0\n",
        "\t\tcorrect = 0 # classification\n",
        "\t\ttotal = 0\n",
        "\t\tall_preds = []\n",
        "\t\tall_targets = []\n",
        "\t\t\n",
        "\t\tfor train_x, train_y in self.train_loader: # batch training\n",
        "\t\t\ttrain_x, train_y = train_x.to(self.cfg.device), train_y.to(self.cfg.device)\n",
        "\t\t\t\n",
        "\t\t\tself.optimizer.zero_grad() # ì´ì „ gradient ì´ˆê¸°í™”\n",
        "\t\t\toutputs = self.model(train_x)\n",
        "\t\t\tloss = self.criterion(outputs, train_y)\n",
        "\t\t\t\n",
        "\t\t\tloss.backward() # backward pass\n",
        "\t\t\tself.optimizer.step() # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
        "\t\t\tif self.cfg.scheduler_name == \"OneCycleLR\":\n",
        "\t\t\t\tself.scheduler.step()\n",
        "\t\t\t\n",
        "\t\t\trunning_loss += loss.item() * train_y.size(0) # train_loss \n",
        "\t\t\t_, predicted = torch.max(outputs, 1) # ê°€ì¥ í™•ë¥  ë†’ì€ í´ë˜ìŠ¤ ì˜ˆì¸¡ # classification\n",
        "\t\t\tcorrect += (predicted == train_y).sum().item() # classification\n",
        "\t\t\ttotal += train_y.size(0) \n",
        "\n",
        "\t\t\tall_preds.extend(predicted.cpu().numpy())\n",
        "\t\t\tall_targets.extend(train_y.cpu().numpy())\n",
        "\t\t\t\n",
        "\t\tepoch_loss = running_loss / total # average loss of 1 epoch\n",
        "\t\tepoch_acc = 100 * correct / total # classification\n",
        "\t\tepoch_f1 = f1_score(all_targets, all_preds, average='macro') # classification\n",
        "\t\treturn epoch_loss, epoch_acc, epoch_f1  # classification\t\t\n",
        "\t\n",
        "\tdef validation_step(self):\n",
        "\t\tself.model.eval()  # í‰ê°€ ëª¨ë“œ\n",
        "\t\tval_loss = 0\n",
        "\t\tcorrect = 0 # classification\n",
        "\t\ttotal = 0\n",
        "\t\tall_preds = []\n",
        "\t\tall_targets = []\n",
        "\t\t\n",
        "\t\twith torch.no_grad():  # gradient ê³„ì‚° ë¹„í™œì„±í™”\n",
        "\t\t\tfor val_x, val_y in self.valid_loader: # batch training\n",
        "\t\t\t\tval_x, val_y = val_x.to(self.cfg.device), val_y.to(self.cfg.device)\n",
        "\t\t\t\t\n",
        "\t\t\t\toutputs = self.model(val_x)\n",
        "\t\t\t\tloss = self.criterion(outputs, val_y)\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\tval_loss += loss.item() * val_y.size(0)\n",
        "\t\t\t\t_, predicted = torch.max(outputs, 1) # classification\n",
        "\t\t\t\tcorrect += (predicted == val_y).sum().item() # classification\n",
        "\t\t\t\ttotal += val_y.size(0)\n",
        "\n",
        "\t\t\t\tall_preds.extend(predicted.cpu().numpy())\n",
        "\t\t\t\tall_targets.extend(val_y.cpu().numpy())\n",
        "\t\t\n",
        "\t\tepoch_loss = val_loss / total # average loss of 1 epoch\n",
        "\t\tepoch_acc = 100 * correct / total # classification\n",
        "\t\tepoch_f1 = f1_score(all_targets, all_preds, average='macro') # classification\n",
        "\t\treturn epoch_loss, epoch_acc, epoch_f1 # classification\n",
        "\t\n",
        "\tdef training_loop(self):\n",
        "\t\ttry:\n",
        "\t\t\t# reset loss list for plots\n",
        "\t\t\tself.train_losses_for_plot, self.val_losses_for_plot = [], []\n",
        "\t\t\tself.train_acc_for_plot, self.val_acc_for_plot = [], []\n",
        "\t\t\tepoch_counter = 0\n",
        "\t\t\tepoch_timer = []\n",
        "\t\t\tdone = False\n",
        "\t\t\t\n",
        "\t\t\tpbar = tqdm(total=self.cfg.epochs)\n",
        "\t\t\twhile not done and epoch_counter<self.cfg.epochs:\n",
        "\t\t\t\tst = time.time()\n",
        "\t\t\t\tepoch_counter += 1\n",
        "\t\t\t\t\n",
        "\t\t\t\t# train\n",
        "\t\t\t\t# train_loss = self.training_step() # regression\n",
        "\t\t\t\ttrain_loss, train_acc, train_f1 = self.training_step() # classification\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.train_losses_for_plot.append(train_loss)\n",
        "\t\t\t\tself.train_acc_for_plot.append(train_acc) # classification\n",
        "\t\t\t\tself.train_f1_for_plot.append(train_f1) # classification\n",
        "\t\t\t\t\n",
        "\t\t\t\t# validation\n",
        "\t\t\t\t# val_loss = self.validation_step() # regression\n",
        "\t\t\t\tval_loss, val_acc, val_f1 = self.validation_step()  # classification\n",
        "\t\t\t\tself.val_losses_for_plot.append(val_loss)\n",
        "\t\t\t\tself.val_acc_for_plot.append(val_acc) # classification\n",
        "\t\t\t\tself.val_f1_for_plot.append(val_f1) # classification\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\t\t# schedulerì˜ ì¢…ë¥˜ì— ë”°ë¼ val_lossë¥¼ ì „ë‹¬í•˜ê±°ë‚˜ ê·¸ëƒ¥ step() í˜¸ì¶œ.\n",
        "\t\t\t\tif self.cfg.scheduler_name == \"OneCycleLR\":\n",
        "\t\t\t\t\tpass\n",
        "\t\t\t\telif self.cfg.scheduler_name == \"ReduceLROnPlateau\":\n",
        "\t\t\t\t\tself.scheduler.step(val_loss)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tself.scheduler.step()\n",
        "\t\t\t\tepoch_timer.append(time.time() - st)\n",
        "\t\t\t\tpbar.update(1)\n",
        "\t\t\t\tif self.es(self.model, val_loss):\n",
        "\t\t\t\t\t# early stopped ëœ ê²½ìš° if ë¬¸ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¨ë‹¤.\n",
        "\t\t\t\t\tdone = True\n",
        "\t\t\t\tif self.run is not None:\n",
        "\t\t\t\t\tprint('wandb logging...')\n",
        "\t\t\t\t\tepoch_log = {\n",
        "\t\t\t\t\t\t'train_loss': train_loss,\n",
        "\t\t\t\t\t\t'train_accuracy': train_acc,\n",
        "\t\t\t\t\t\t'train_f1': train_f1,\n",
        "\t\t\t\t\t\t'val_loss': val_loss,\n",
        "\t\t\t\t\t\t'val_accuracy': val_acc,\n",
        "\t\t\t\t\t\t'val_f1': val_f1\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t\trun.log(epoch_log, step=epoch_counter) # wandb logging\n",
        "\t\t\t\tif epoch_counter == 1 or epoch_counter % self.verbose == 0:\n",
        "\t\t\t\t\t# self.verbose epochë§ˆë‹¤ logging\n",
        "\t\t\t\t\tmean_time_spent = np.mean(epoch_timer)\n",
        "\t\t\t\t\tepoch_timer = [] # reset timer list\n",
        "\t\t\t\t\t# print(f\"Epoch {epoch_counter}/{self.cfg.epochs} [Time: {mean_time_spent:.2f}s], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.8f}\")\n",
        "\t\t\t\t\tprint(f\"Epoch {epoch_counter}/{self.cfg.epochs} [Time: {mean_time_spent:.2f}s], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.8f}\\n Train ACC: {train_acc:.2f}%, Validation ACC: {val_acc:.2f}%\\n Train F1: {train_f1:.4f}, Validation F1: {val_f1:.4f}\") # classification\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(e)\n",
        "\t\t\treturn False # training loop failed\n",
        "\t\treturn True # training loop succeed\n",
        "\t\t\n",
        "\tdef plot_loss(self, show:bool=False, savewandb:bool=True, savedir:str=None):\n",
        "\t\t\"\"\"loss, accuracy, f1-scoreì— ëŒ€í•œ ê·¸ë˜í”„ ì‹œê°í™” í•¨ìˆ˜\n",
        "\n",
        "\t\t:param bool show: plt.show()ë¥¼ ì‹¤í–‰í•  ê±´ì§€, defaults to False\n",
        "\t\t:param bool savewandb: wandb loggingì— plotì„ ì‹œê°í™”í•˜ì—¬ ì €ì¥í•  ê±´ì§€, defaults to True\n",
        "\t\t:param str savedir: plotì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ ì„¤ì •, Noneì´ë©´ ì €ì¥ ì•ˆ í•¨, defaults to None\n",
        "\t\t:return _type_: None\n",
        "\t\t\"\"\"\n",
        "\t\timport matplotlib.pyplot as plt\n",
        "\t\tfig, ax = plt.subplots(figsize=(6, 4))\n",
        "\t\tplt.plot(range(len(self.train_losses_for_plot)),self.train_losses_for_plot,color='blue',label='train_loss')\n",
        "\t\tplt.plot(range(len(self.val_losses_for_plot)),self.val_losses_for_plot,color='red',label='val_loss')\n",
        "\t\tplt.axhline(y=1e-3, color='red', linestyle='--', label='(Overfit)')\n",
        "\t\tplt.legend()\n",
        "\t\tplt.xlabel(\"Epoch\")\n",
        "\t\tplt.ylabel(\"Loss\")\n",
        "\t\tplt.title(\"Train/Validation Loss plot\")\n",
        "\t\tif savedir is not None:\n",
        "\t\t\tif os.path.exists(savedir):\n",
        "\t\t\t\tos.makedirs(savedir, exist_ok=True)\n",
        "\t\t\tsavepath = os.path.join(savedir, \"loss_plot.png\")\n",
        "\t\t\tplt.savefig(savepath)\n",
        "\t\t\tprint(f\"âš™ï¸loss plot saved in {savepath}\")\n",
        "\t\tif show:\n",
        "\t\t\tplt.show()\n",
        "\t\tif savewandb and self.run is not None:\n",
        "\t\t\trun.log({'loss_plot': wandb.Image(fig)}) # wandb\n",
        "\t\tplt.clf()\n",
        "\t\t\n",
        "\t\t# classification\n",
        "\t\tfig, ax = plt.subplots(figsize=(6, 4))\n",
        "\t\tplt.plot(range(len(self.train_acc_for_plot)),self.train_acc_for_plot,color='blue',label='train_acc')\n",
        "\t\tplt.plot(range(len(self.val_acc_for_plot)),self.val_acc_for_plot,color='red',label='val_acc')\n",
        "\t\tplt.axhline(y=99.0, color='red', linestyle='--', label='(99%)')\n",
        "\t\tplt.legend()\n",
        "\t\tplt.xlabel(\"Epoch\")\n",
        "\t\tplt.ylabel(\"Accuracy(%)\")\n",
        "\t\tplt.title(\"Train/Validation Accuracy Plot\")\n",
        "\t\tplt.grid()\n",
        "\t\tif savedir is not None:\n",
        "\t\t\tsavepath = os.path.join(savedir, \"accuracy_plot.png\")\n",
        "\t\t\tplt.savefig(savepath)\n",
        "\t\t\tprint(f\"âš™ï¸accuracy plot saved in {savepath}\")\n",
        "\t\tif show:\n",
        "\t\t\tplt.show()\n",
        "\t\tif savewandb and self.run is not None:\n",
        "\t\t\trun.log({'accuracy_plot': wandb.Image(fig)}) # wandb\n",
        "\t\tplt.clf()\n",
        "\n",
        "\t\t# classification\n",
        "\t\tfig, ax = plt.subplots(figsize=(6, 4))\n",
        "\t\tplt.plot(range(len(self.train_f1_for_plot)),self.train_f1_for_plot,color='blue',label='train_f1')\n",
        "\t\tplt.plot(range(len(self.val_f1_for_plot)),self.val_f1_for_plot,color='red',label='val_f1')\n",
        "\t\tplt.axhline(y=0.99, color='red', linestyle='--', label='(0.99)')\n",
        "\t\tplt.legend()\n",
        "\t\tplt.xlabel(\"Epoch\")\n",
        "\t\tplt.ylabel(\"F1-score\")\n",
        "\t\tplt.title(\"Train/Validation F1-score Plot\")\n",
        "\t\tplt.grid()\n",
        "\t\tif savedir is not None:\n",
        "\t\t\tsavepath = os.path.join(savedir, \"f1_plot.png\")\n",
        "\t\t\tplt.savefig(savepath)\n",
        "\t\t\tprint(f\"âš™ï¸f1 plot saved in {savepath}\")\n",
        "\t\tif show:\n",
        "\t\t\tplt.show()\n",
        "\t\tif savewandb and self.run is not None:\n",
        "\t\t\trun.log({'f1_plot': wandb.Image(fig)}) # wandb\n",
        "\t\tplt.clf()\n",
        "\t\treturn None\n",
        "\t\t\n",
        "\tdef save_experiments(self, savepath=None):\n",
        "\t\t\"\"\"\"\"\"\n",
        "\t\tsave_dict = {\n",
        "\t\t\t'model_state_dict': self.model.state_dict(),\n",
        "\t\t\t'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "\t\t\t'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "\t\t\t'cfg': vars(self.cfg) # ë‚˜ì¤‘ì— ë¡œë“œí•´ì„œ CFG = SimpleNamespace(**cfg)ë¡œ ë³µì›\n",
        "\t\t}\n",
        "\t\tif savepath is not None:\n",
        "\t\t\tdirpath = os.path.dirname(savepath)\n",
        "\t\t\tif os.path.exists(dirpath):\n",
        "\t\t\t\tos.makedirs(dirpath, exist_ok=True)\n",
        "\t\t\ttorch.save(save_dict, f=savepath)\n",
        "\t\t\treturn True\n",
        "\t\treturn False\n",
        "\t\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amum-FlIojc6"
      },
      "source": [
        "## 3. Load Data & Augmentation\n",
        "* í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "* ì´ë¯¸ì§€ ì¦ê°• ê¸°ë²•ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "> references   \n",
        "> - torchvision ì§ì ‘ êµ¬í˜„ : [ì˜ˆì‹œ ì½”ë“œ](https://skier-song9.notion.site/CustomDataset-Augmentation-1d1c8d3f60f58026b4def1895f3fb9b0?source=copy_link)   \n",
        "> - Albumentation : [ì˜ˆì‹œ ì½”ë“œ](https://albumentations.ai/docs/examples/)   \n",
        "> - Augraphy : [ì˜ˆì‹œ ì½”ë“œ](https://augraphy.readthedocs.io/en/latest/doc/source/example_usage.html), [PyTorch í”„ë¡œì„¸ìŠ¤ì—ì„œ ì‚¬ìš© ë°©ë²•](https://augraphy.readthedocs.io/en/latest/examples/pytorch_integration_classification_example.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "album_basic_transform = A.Compose(\n",
        "    [\n",
        "        A.SmallestMaxSize(max_size=CFG.image_size),\n",
        "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=360, p=1),\n",
        "        A.RandomCrop(height=CFG.image_size, width=CFG.image_size),\n",
        "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=1),\n",
        "        A.RandomBrightnessContrast(p=1),\n",
        "        A.Normalize(mean=CFG.norm_mean, std=CFG.norm_mean),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "llh5C7ZKoq2S"
      },
      "outputs": [],
      "source": [
        "# augmentationì„ ìœ„í•œ transform ì½”ë“œ\n",
        "train_transform = A.Compose([\n",
        "    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •\n",
        "    A.Resize(height=CFG.image_size, width=CFG.image_size),\n",
        "    # images normalization\n",
        "    A.Normalize(mean=CFG.norm_mean, std=CFG.norm_std),\n",
        "    # numpy ì´ë¯¸ì§€ë‚˜ PIL ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# valid, test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ\n",
        "test_transform = A.Compose([\n",
        "    A.Resize(height=CFG.image_size, width=CFG.image_size),\n",
        "    A.Normalize(mean=CFG.norm_mean, std=CFG.norm_std),\n",
        "    ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# í›ˆë ¨ ë°ì´í„°ì…‹ ì¦ê°•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train-validation split\n",
        "### TO-DO\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.int64'>\n"
          ]
        }
      ],
      "source": [
        "# í´ë˜ìŠ¤ ë¼ë²¨ì˜ íƒ€ì… í™•ì¸\n",
        "print(type(train_df.iloc[0, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = os.path.join(data_dir, \"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ë°©ë²•1(CROP or CUTOUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Crop ì¦ê°• íŒŒì´í”„ë¼ì¸ ì„¤ì •\n",
        "# augment = A.Compose([\n",
        "#     # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •\n",
        "#     A.RandomResizedCrop(\n",
        "#         height=CFG.image_size, width=CFG.image_size,\n",
        "#         scale=(0.85, 0.95),  # ìµœì†Œ 85%, ìµœëŒ€ 95% ì˜ì—­ì„ crop\n",
        "#         ratio=(0.9, 1.1),    # ì¢…íš¡ë¹„ ìœ ì§€, ì•½ê°„ì˜ ë¹„ìœ¨ ë³€í™” í—ˆìš©\n",
        "#         p=1.0\n",
        "#     )\n",
        "# ])\n",
        "\n",
        "# Cutout ì¦ê°• íŒŒì´í”„ë¼ì¸ ì„¤ì •\n",
        "augment = A.Compose([\n",
        "    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •\n",
        "    A.Cutout(\n",
        "        num_holes=1,                  # ë§ˆìŠ¤í‚¹ ì˜ì—­ ê°œìˆ˜\n",
        "        max_h_size=int(CFG.image_size * 0.2),   # ë†’ì´ ìµœëŒ€ 10% (ì˜ˆ: 224pxì´ë©´ 22px)\n",
        "        max_w_size=int(CFG.image_size * 0.4),   # ë„ˆë¹„ ìµœëŒ€ 20% (ì˜ˆ: 224pxì´ë©´ 44px)\n",
        "        fill_value=0,                 # ê²€ì •ìƒ‰ ë°•ìŠ¤ ë§ˆìŠ¤í‚¹\n",
        "        p=1                         # 50% í™•ë¥ ë¡œ ì ìš©\n",
        "    )\n",
        "])\n",
        "\n",
        "# ì¦ê°• ëŒ€ìƒ í´ë˜ìŠ¤\n",
        "augment_classes = [1, 13, 14]\n",
        "max_samples = 90\n",
        "\n",
        "# ì¦ê°• ì´ë¯¸ì§€, ë¼ë²¨, ID ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
        "augmented_labels = []    # ì¦ê°•ëœ ì´ë¯¸ì§€ ë¼ë²¨\n",
        "augmented_ids = []       # ì¦ê°•ëœ ì´ë¯¸ì§€ ID\n",
        "\n",
        "# ì¦ê°• ëŒ€ìƒ í´ë˜ìŠ¤ ë£¨í”„\n",
        "for cls in augment_classes:\n",
        "    cls_df = train_df[train_df['target'] == cls]\n",
        "    current_count = len(cls_df)\n",
        "\n",
        "    if current_count * 2 < max_samples:\n",
        "        # ëª¨ë“  ì´ë¯¸ì§€ 1íšŒì”© ì¦ê°•\n",
        "        for idx, row in cls_df.iterrows():\n",
        "            img_id = row['ID']\n",
        "            img_path = os.path.join(data_dir, img_id)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            augmented = augment(image=img)['image']\n",
        "\n",
        "            new_id = f\"aug_{img_id}\"\n",
        "            save_path = os.path.join(data_dir, new_id)\n",
        "\n",
        "            cv2.imwrite(save_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            augmented_labels.append(cls)\n",
        "            augmented_ids.append(new_id)\n",
        "\n",
        "    else:\n",
        "        to_generate = max_samples - current_count\n",
        "        \n",
        "        if to_generate <= 0:\n",
        "            continue\n",
        "\n",
        "        # í•œ ë²ˆì— to_generate ë§Œí¼ ëœë¤ ìƒ˜í”Œë§\n",
        "        sampled_df = cls_df.sample(n=to_generate, replace=False, random_state=42).reset_index(drop=True)\n",
        "        \n",
        "        for i, row in sampled_df.iterrows():\n",
        "            img_id = row['ID']\n",
        "\n",
        "            # ì´ë¯¸ì§€ ë¡œë“œ\n",
        "            img_path = f\"{data_dir}/{img_id}\"\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # ì¦ê°•\n",
        "            augmented = augment(image=img)['image']\n",
        "\n",
        "            # ì €ì¥í•  íŒŒì¼ëª… ë° ê²½ë¡œ\n",
        "            new_id = f\"aug_{img_id}\"\n",
        "            save_path = os.path.join(data_dir, new_id)\n",
        "\n",
        "            # RGB â†’ BGR ë³€í™˜ í›„ ì €ì¥\n",
        "            cv2.imwrite(save_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            augmented_labels.append(cls)          # ë¼ë²¨\n",
        "            augmented_ids.append(new_id)          # ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ë°©ë²•1-1(ì¦ê°• ì ìš© í›„ ë˜ ì¦ê°• ì ìš©)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # ì¦ê°• íŒŒì´í”„ë¼ì¸ ì„¤ì •\n",
        "# augment = A.Compose([\n",
        "#     A.Cutout(\n",
        "#         num_holes=1,\n",
        "#         max_h_size=int(CFG.image_size * 0.1),\n",
        "#         max_w_size=int(CFG.image_size * 0.2),\n",
        "#         fill_value=0,\n",
        "#         p=1\n",
        "#     )\n",
        "# ])\n",
        "\n",
        "# augment_classes = [1, 13, 14]\n",
        "# max_samples = 100\n",
        "\n",
        "# augmented_labels = []\n",
        "# augmented_ids = []\n",
        "\n",
        "# for cls in augment_classes:\n",
        "#     cls_df = train_df[train_df['target'] == cls].reset_index(drop=True)\n",
        "#     current_count = len(cls_df)\n",
        "\n",
        "#     if current_count * 2 < max_samples:\n",
        "#         # ëª¨ë“  ì´ë¯¸ì§€ 1íšŒì”© ì¦ê°•\n",
        "#         for idx, row in cls_df.iterrows():\n",
        "#             img_id = row['ID']\n",
        "#             img_path = os.path.join(data_dir, img_id)\n",
        "#             img = cv2.imread(img_path)\n",
        "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#             augmented = augment(image=img)['image']\n",
        "\n",
        "#             new_id = f\"aug_{img_id}\"\n",
        "#             save_path = os.path.join(data_dir, new_id)\n",
        "\n",
        "#             cv2.imwrite(save_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "#             augmented_labels.append(cls)\n",
        "#             augmented_ids.append(new_id)\n",
        "\n",
        "#         # ë¶€ì¡±í•œ ìˆ˜ ë§Œí¼ ì¦ê°•ëœ ì´ë¯¸ì§€ì—ì„œ ì¶”ê°€ ì¦ê°•\n",
        "#         additional_needed = max_samples - (current_count * 2)\n",
        "#         augmented_df = pd.DataFrame({'ID': augmented_ids[-current_count:], 'target': [cls]*current_count})\n",
        "\n",
        "#         sampled_df = augmented_df.sample(n=additional_needed, replace=True, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#         for idx, row in sampled_df.iterrows():\n",
        "#             img_id = row['ID']\n",
        "#             img_path = os.path.join(data_dir, img_id)\n",
        "#             img = cv2.imread(img_path)\n",
        "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#             augmented = augment(image=img)['image']\n",
        "\n",
        "#             new_id = f\"aug2_{img_id}\"\n",
        "#             save_path = os.path.join(data_dir, new_id)\n",
        "\n",
        "#             cv2.imwrite(save_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "#             augmented_labels.append(cls)\n",
        "#             augmented_ids.append(new_id)\n",
        "\n",
        "#     else:\n",
        "#         # ê¸°ì¡´ ë¡œì§: ë¶€ì¡±í•œ ë§Œí¼ë§Œ ì¦ê°•\n",
        "#         to_generate = max_samples - current_count\n",
        "#         if to_generate <= 0:\n",
        "#             continue\n",
        "\n",
        "#         sampled_df = cls_df.sample(n=to_generate, replace=False, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#         for idx, row in sampled_df.iterrows():\n",
        "#             img_id = row['ID']\n",
        "#             img_path = os.path.join(data_dir, img_id)\n",
        "#             img = cv2.imread(img_path)\n",
        "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#             augmented = augment(image=img)['image']\n",
        "\n",
        "#             new_id = f\"aug_{img_id}\"\n",
        "#             save_path = os.path.join(data_dir, new_id)\n",
        "\n",
        "#             cv2.imwrite(save_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "#             augmented_labels.append(cls)\n",
        "#             augmented_ids.append(new_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ë°©ë²•2(MIXUP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def mixup_images_numpy(img1, img2, alpha=0.4):\n",
        "#     lam = np.random.beta(alpha, alpha)\n",
        "#     mixed = lam * img1.astype(np.float32) + (1 - lam) * img2.astype(np.float32)\n",
        "#     mixed = np.clip(mixed, 0, 255).astype(np.uint8)\n",
        "#     return mixed\n",
        "\n",
        "# augment_classes = [1, 13, 14]\n",
        "# max_samples = 74\n",
        "\n",
        "# augmented_labels = []\n",
        "# augmented_ids = []\n",
        "\n",
        "# for cls in augment_classes:\n",
        "#     cls_df = train_df[train_df['target'] == cls].reset_index(drop=True)\n",
        "#     current_count = len(cls_df)\n",
        "#     to_generate = max_samples - current_count\n",
        "\n",
        "#     if to_generate <= 0:\n",
        "#         continue\n",
        "\n",
        "#     # ID ë¦¬ìŠ¤íŠ¸\n",
        "#     id_list = cls_df['ID'].tolist()\n",
        "\n",
        "#     # ê°€ëŠ¥í•œ ëª¨ë“  (id1, id2) ì¡°í•© ìƒì„±, ìê¸° ìì‹ ê³¼ ì¡°í•© ì œì™¸\n",
        "#     possible_pairs = list(itertools.combinations(id_list, 2))\n",
        "\n",
        "#     # to_generate ë§Œí¼ ëœë¤ ìƒ˜í”Œë§\n",
        "#     sampled_pairs = random.sample(possible_pairs, min(to_generate, len(possible_pairs)))\n",
        "\n",
        "#     for id1, id2 in sampled_pairs:\n",
        "#         # ì´ë¯¸ì§€ 1\n",
        "#         img_path1 = os.path.join(data_dir, id1)\n",
        "#         img1 = cv2.imread(img_path1)\n",
        "#         img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "#         img1 = cv2.resize(img1, (443, 591), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "#         # ì´ë¯¸ì§€ 2\n",
        "#         img_path2 = os.path.join(data_dir, id2)\n",
        "#         img2 = cv2.imread(img_path2)\n",
        "#         img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "#         img2 = cv2.resize(img2, (443, 591), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "#         # mixup\n",
        "#         mixed_img = mixup_images_numpy(img1, img2, alpha=0.4)\n",
        "\n",
        "#         name1 = os.path.splitext(id1)[0]\n",
        "#         name2 = os.path.splitext(id2)[0]\n",
        "\n",
        "#         # ì €ì¥í•  íŒŒì¼ëª… ë° ê²½ë¡œ\n",
        "#         new_id = f\"aug_{name1}_{name2}.jpg\"\n",
        "#         save_path = os.path.join(data_dir, new_id)  # í•„ìš”ì‹œ aug_dirë¡œ ë³€ê²½ ê°€ëŠ¥\n",
        "\n",
        "#         # RGB â†’ BGR í›„ ì €ì¥\n",
        "#         cv2.imwrite(save_path, cv2.cvtColor(mixed_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "#         augmented_labels.append(cls)\n",
        "#         augmented_ids.append(new_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = os.path.join(project_root, 'data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¦ê°•ëœ ë°ì´í„°ìš© IDì™€ ë¼ë²¨ë§Œ DataFrame ìƒì„± (ì´ë¯¸ì§€ ë°°ì—´ ì œì™¸)\n",
        "aug_df = pd.DataFrame({\n",
        "    'ID': augmented_ids,      # ì´ë¯¸ì§€ ë°°ì—´ì´ ì•„ë‹ˆë¼ ID ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©\n",
        "    'target': augmented_labels\n",
        "})\n",
        "\n",
        "# ê¸°ì¡´ ë°ì´í„°ì™€ ì¦ê°• ë°ì´í„° ë³‘í•© (ì´ë¯¸ì§€ëŠ” ë³„ë„ ê´€ë¦¬)\n",
        "combined_train_df = pd.concat([train_df, aug_df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train-Validation ë¶„í• "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # ì¦ê°• ë¯¸ ì§„í–‰ ì‹œ í™œì„±í™”\n",
        "# combined_train_df = train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1419 251\n"
          ]
        }
      ],
      "source": [
        "train_idx, val_idx = train_test_split(\n",
        "    range(len(combined_train_df)),\n",
        "    test_size=CFG.val_split_ratio,\n",
        "    stratify=combined_train_df['target'],\n",
        "    shuffle=True,\n",
        "    random_state=CFG.random_seed\n",
        ")\n",
        "print(len(train_idx), len(val_idx))\n",
        "\n",
        "# Create train and validation CSV files temporarily\n",
        "train_subset = combined_train_df.iloc[train_idx].reset_index(drop=True)\n",
        "val_subset = combined_train_df.iloc[val_idx].reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dataset ë° DataLoader ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INxdmsStop2L",
        "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1419 251 3140\n"
          ]
        }
      ],
      "source": [
        "# Dataset ì •ì˜\n",
        "train_dataset = ImageDataset(\n",
        "    train_subset,\n",
        "    os.path.join(data_dir, \"train\"),\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "# Augmented Dataset ì •ì˜\n",
        "album_basic_dataset = ImageDataset(\n",
        "    train_subset,\n",
        "    os.path.join(data_dir, \"train\"),\n",
        "    transform=album_basic_transform\n",
        ")\n",
        "\n",
        "# Concat Train Datasets\n",
        "combined_dataset = ConcatDataset(\n",
        "    [train_dataset, album_basic_dataset]\n",
        ")\n",
        "\n",
        "\n",
        "valid_dataset = ImageDataset(\n",
        "    val_subset,\n",
        "    os.path.join(data_dir, \"train\"),\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "test_dataset = ImageDataset(\n",
        "    pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\")),\n",
        "    os.path.join(data_dir, \"test\"),\n",
        "    transform=test_transform\n",
        ")\n",
        "print(len(train_dataset), len(valid_dataset), len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_sO03fWaQj1h"
      },
      "outputs": [],
      "source": [
        "# DataLoader ì •ì˜\n",
        "train_loader = DataLoader(\n",
        "    combined_dataset,\n",
        "    batch_size=CFG.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=CFG.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=CFG.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "for train_x, train_y in train_loader:\n",
        "    print(train_x.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmm5h3J-pXNV"
      },
      "source": [
        "## 5. Train Model\n",
        "* ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_activation(CFG):\n",
        "    ACTIVATIONS = {\n",
        "        'ReLU': nn.ReLU, # ìŒìˆ˜ëŠ” 0ìœ¼ë¡œ, ì–‘ìˆ˜ëŠ” ì„ í˜•í•¨ìˆ˜\n",
        "        'LeakyReLU': nn.LeakyReLU, # ìŒìˆ˜ë„ ì¼ë¶€ í†µê³¼ -> Dead ReLU ë°©ì§€\n",
        "        'ELU': nn.ELU, # ìŒìˆ˜ë„ ì¼ë¶€ í†µê³¼ â†’ ì¶œë ¥ í‰ê· ì´ 0ì— ê°€ê¹ë„ë¡ í•¨ìœ¼ë¡œì¨ í•™ìŠµ ì•ˆì •í™” ë„ì›€\n",
        "        'SELU': nn.SELU, # ELUì— ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜ë¥¼ ê³±í•´ ì‹ ê²½ë§ì„ ìê¸° ì •ê·œí™”, íŠ¹ì • ì¡°ê±´ (ì˜ˆ: fully connected, íŠ¹ì • ì´ˆê¸°í™”, íŠ¹ì • êµ¬ì¡°)ì—ì„œë§Œ ìê¸° ì •ê·œí™” íš¨ê³¼ê°€ ì˜ ë°œíœ˜\n",
        "        'GELU': nn.GELU, # ë” ë¶€ë“œëŸ¬ìš´ ë¹„ì„ í˜•ì„±, Transformer, BERTë¥˜\n",
        "        'Tanh': nn.Tanh, # ì™„ë§Œí•œ sigmoid\n",
        "        'PReLU': nn.PReLU, # ìŒìˆ˜ë„ ì¼ë¶€ í†µê³¼ -> Dead ReLU ë°©ì§€, ê¸°ìš¸ê¸°ë¥¼ í•™ìŠµí•¨.\n",
        "        'SiLU': nn.SiLU, # ë” ë¶€ë“œëŸ¬ìš´ ë¹„ì„ í˜•ì„±, EfficientNet, Swin Transformer ë“±\n",
        "    }\n",
        "    return ACTIVATIONS[CFG.activation]\n",
        "\n",
        "class TimmWrapper(nn.Module):\n",
        "    def __init__(self, CFG):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            model_name=CFG.model_name,\n",
        "            pretrained=CFG.pretrained,\n",
        "            num_classes=0, global_pool='avg'\n",
        "        )\n",
        "        self.dropout = nn.Dropout(p=CFG.dropout)\n",
        "        self.activation = get_activation(CFG)()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.backbone.num_features, 1000),\n",
        "            nn.BatchNorm1d(1000),\n",
        "            self.activation,\n",
        "            self.dropout,\n",
        "            nn.Linear(1000, 17)\n",
        "        )\n",
        "        def weight_init(m):\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                if CFG.timm_activation in ['Tanh']:\n",
        "                    # Xavier ì´ˆê¸°í™”\n",
        "                    init.xavier_uniform_(m.weight)\n",
        "                else:\n",
        "                    # He ì´ˆê¸°í™”\n",
        "                    init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm1d) or isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "        if CFG.fine_tuning == 'head':\n",
        "            # backbone íŒŒë¼ë¯¸í„°ë¥¼ freeze\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = False\n",
        "            # classifierëŠ” ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
        "            self.classifier.apply(weight_init)\n",
        "        elif CFG.fine_tuning == 'custom':\n",
        "            # ì§ì ‘ ì»¤ìŠ¤í„°ë§ˆì´ì§•\n",
        "            pass\n",
        "        elif CFG.fine_tuning == 'scratch':\n",
        "            self.apply(weight_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def get_timm_model(CFG):\n",
        "    if CFG.dropout is not None:\n",
        "        return TimmWrapper(CFG).to(CFG.device)\n",
        "\n",
        "    return timm.create_model(\n",
        "        CFG.model_name,\n",
        "        pretrained=CFG.pretrained,\n",
        "        num_classes=17,\n",
        "        act_layer=CFG.timm_activation # activation function ì„¤ì • (pretrained=Trueë¼ë©´ pretrainedì˜ activationì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.)\n",
        "    ).to(CFG.device)\n",
        "\n",
        "def get_criterion(CFG):\n",
        "    CRITERIONS = {\n",
        "        \"CrossEntropyLoss\" : nn.CrossEntropyLoss()\n",
        "    }\n",
        "    return CRITERIONS[CFG.criterion]\n",
        "\n",
        "def get_optimizers(model, CFG):\n",
        "    # SGD, RMSprop, Momentum, NAG, Adam, AdamW, NAdam, RAdam, Adafactor\n",
        "    OPTIMIZERS = {\n",
        "        'SGD': optim.SGD(model.parameters(), lr=CFG.lr),\n",
        "        'RMSprop': optim.RMSprop(model.parameters(), lr=CFG.lr, alpha=0.99, weight_decay=CFG.weight_decay),\n",
        "        'Momentum': optim.SGD(model.parameters(), lr=CFG.lr, momentum=0.9),\n",
        "        'NAG' : optim.SGD(model.parameters(), lr=CFG.lr, momentum=0.9, nesterov=True),\n",
        "        'Adam' : optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay),\n",
        "        'AdamW': optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay),\n",
        "        'NAdam': optim.NAdam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, momentum_decay=4e-3),\n",
        "        'RAdam': optim.RAdam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay),\n",
        "        'Adafactor': optim.Adafactor(model.parameters(), lr=CFG.lr, beta2_decay=-0.8, d=1.0, weight_decay=CFG.weight_decay, maximize=False)\n",
        "    }\n",
        "    return OPTIMIZERS[CFG.optimizer_name]\n",
        "\n",
        "def get_scheduler(optimizer, CFG):\n",
        "    # StepLR, ExponentialLR, CosineAnnealingLR, OneCycleLR, ReduceLROnPlateau\n",
        "    SCHEDULERS = {\n",
        "        'StepLR': lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1),\n",
        "        'ExponentialLR': lr_scheduler.ExponentialLR(optimizer, gamma=0.95),\n",
        "        'CosineAnnealingLR': lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs, eta_min=0),\n",
        "        'OneCycleLR': lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=CFG.epochs),\n",
        "        'ReduceLROnPlateau': lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=CFG.patience-5, min_lr=0),\n",
        "    }\n",
        "    return SCHEDULERS[CFG.scheduler_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FbBgFPsLT-CO"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "model = get_timm_model(CFG)\n",
        "\n",
        "criterion = get_criterion(CFG)\n",
        "\n",
        "# define optimizer\n",
        "# SGD, RMSprop, Momentum, NAG, Adam, AdamW, NAdam, RAdam, Adafactor\n",
        "optimizer = get_optimizers(model, CFG)\n",
        "\n",
        "# define scheduler\n",
        "# StepLR, ExponentialLR, CosineAnnealingLR, OneCycleLR, ReduceLROnPlateau\n",
        "scheduler = get_scheduler(optimizer, CFG)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = TrainModule(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    cfg=CFG,\n",
        "    verbose=15,\n",
        "    run=run\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TimmWrapper(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (act1): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (activation): SELU()\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): SELU()\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Linear(in_features=1000, out_features=17, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/10000 [00:08<22:46:39,  8.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000 [Time: 8.20s], Train Loss: 1.1579, Validation Loss: 0.51033927\n",
            " Train ACC: 62.54%, Validation ACC: 82.47%\n",
            " Train F1: 0.6164, Validation F1: 0.8206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 15/10000 [01:54<21:05:51,  7.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/10000 [Time: 7.57s], Train Loss: 0.0755, Validation Loss: 0.18062885\n",
            " Train ACC: 97.25%, Validation ACC: 93.23%\n",
            " Train F1: 0.9725, Validation F1: 0.9282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 30/10000 [03:48<21:04:15,  7.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/10000 [Time: 7.59s], Train Loss: 0.0358, Validation Loss: 0.26003829\n",
            " Train ACC: 98.73%, Validation ACC: 92.83%\n",
            " Train F1: 0.9872, Validation F1: 0.9223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 45/10000 [05:42<21:04:12,  7.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45/10000 [Time: 7.60s], Train Loss: 0.0277, Validation Loss: 0.26618188\n",
            " Train ACC: 98.84%, Validation ACC: 94.82%\n",
            " Train F1: 0.9885, Validation F1: 0.9452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 46/10000 [05:49<21:02:51,  7.61s/it]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# wandb watch >> layerê°€ ê¹Šìœ¼ë©´ ì–´ì°¨í”¼ ì‹œê°í™”í•´ì„œ ë³´ê¸° ì–´ë ¤ì›€;;\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# if WB:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     run.watch(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# run train\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[8], line 160\u001b[0m, in \u001b[0;36mTrainModule.training_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_f1_for_plot\u001b[38;5;241m.\u001b[39mappend(train_f1) \u001b[38;5;66;03m# classification\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# validation\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# val_loss = self.validation_step() # regression\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m val_loss, val_acc, val_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# classification\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_losses_for_plot\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_acc_for_plot\u001b[38;5;241m.\u001b[39mappend(val_acc) \u001b[38;5;66;03m# classification\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[8], line 117\u001b[0m, in \u001b[0;36mTrainModule.validation_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# gradient ê³„ì‚° ë¹„í™œì„±í™”\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m val_x, val_y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_loader: \u001b[38;5;66;03m# batch training\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \t\tval_x, val_y \u001b[38;5;241m=\u001b[39m val_x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice), val_y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    120\u001b[0m \t\toutputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(val_x)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[0;32mIn[7], line 21\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, name)))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 21\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img, target\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:210\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    207\u001b[0m     p\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transforms):\n\u001b[0;32m--> 210\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_each_transform:\n\u001b[1;32m    213\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_post_transform(data)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:118\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             warn(\n\u001b[1;32m    114\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_class_fullname() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m could work incorrectly in ReplayMode for other input data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m because its\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m params depend on targets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m             )\n\u001b[1;32m    117\u001b[0m         kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_key][\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m deepcopy(params)\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:131\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[0;34m(self, params, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     target_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_function(key)\n\u001b[1;32m    130\u001b[0m     target_dependencies \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_dependence\u001b[38;5;241m.\u001b[39mget(key, [])}\n\u001b[0;32m--> 131\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtarget_dependencies\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/geometric/resize.py:184\u001b[0m, in \u001b[0;36mResize.apply\u001b[0;34m(self, img, interpolation, **params)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_LINEAR, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/utils.py:122\u001b[0m, in \u001b[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_function\u001b[39m(img: np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    121\u001b[0m     shape \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 122\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    124\u001b[0m         result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(result, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py:392\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, height, width, interpolation)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[1;32m    391\u001b[0m resize_fn \u001b[38;5;241m=\u001b[39m _maybe_process_in_chunks(cv2\u001b[38;5;241m.\u001b[39mresize, dsize\u001b[38;5;241m=\u001b[39m(width, height), interpolation\u001b[38;5;241m=\u001b[39minterpolation)\n\u001b[0;32m--> 392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/utils.py:208\u001b[0m, in \u001b[0;36m_maybe_process_in_chunks.<locals>.__process_fn\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    206\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdstack(chunks)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# wandb watch >> layerê°€ ê¹Šìœ¼ë©´ ì–´ì°¨í”¼ ì‹œê°í™”í•´ì„œ ë³´ê¸° ì–´ë ¤ì›€;;\n",
        "# if WB:\n",
        "#     run.watch(\n",
        "#         models=trainer.model,\n",
        "#         criterion=trainer.criterion,\n",
        "#         log='all',\n",
        "#         log_graph=True\n",
        "#     )\n",
        "# run train\n",
        "trainer.training_loop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkwxRXoBpbaX"
      },
      "source": [
        "# 6. Inference & Save File\n",
        "* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ì €ì¥ëœ trainerë¥¼ ë¡œë“œí•˜ì—¬ ì¶”ë¡ í•˜ëŠ” ê²½ìš° ì•„ë˜ í•¨ìˆ˜ë¡œ ë¡œë“œ\n",
        "def load_checkpoint_model(savepath=None):\n",
        "    if os.path.exists(savepath):\n",
        "        checkpoint = torch.load(savepath)\n",
        "        cfg = SimpleNamespace(**checkpoint['cfg'])\n",
        "        model = get_timm_model(cfg)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        return model, cfg\n",
        "    else:\n",
        "        return None\n",
        "    \n",
        "# model, cfg = load_checkpoint_model(\n",
        "#     savepath=os.path.join(project_root,'models','resnetrs101.tf_in1k-opt_Adam-img224-aug_0-2506301324-0001.pth')\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRYe6jlPU_Om",
        "outputId": "2a08690c-9ffe-418d-8679-eb9280147110"
      },
      "outputs": [],
      "source": [
        "preds_list = []\n",
        "\n",
        "trainer.model.eval()\n",
        "for image, _ in tqdm(test_loader):\n",
        "    image = image.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = trainer.model(image)\n",
        "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
        "\n",
        "### checkpointë¡œ ë¡œë“œí•œ ëª¨ë¸ë¡œ ì¶”ë¡ í•˜ëŠ” ê²½ìš°\n",
        "# model.eval()\n",
        "# for image, _ in tqdm(test_loader):\n",
        "#     image = image.to(device)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         preds = model(image)\n",
        "#     preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aClN7Qi7VZoh"
      },
      "outputs": [],
      "source": [
        "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
        "pred_df['target'] = preds_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDBXQqAzVvLY"
      },
      "outputs": [],
      "source": [
        "sample_submission_df = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"))\n",
        "assert (sample_submission_df['ID'] == pred_df['ID']).all(), \"pred_dfì—ì„œ test ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\"\n",
        "assert set(pred_df['target']).issubset(set(range(17))), \"target ì»¬ëŸ¼ì— 0~16 ì™¸ì˜ ê°’ì´ ìˆìŠµë‹ˆë‹¤.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'ì €ì¥í•  Submission íŒŒì¼ ì´ë¦„: {next_run_name}.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### submission íŒŒì¼ ì €ì¥\n",
        "pred_df.to_csv(os.path.join(data_dir, 'submissions', f'{next_run_name}.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### trainer ì €ì¥\n",
        "trainer_savepath = os.path.join(project_root, \"models\", f\"{next_run_name}.pth\")\n",
        "trainer.save_experiments(savepath=trainer_savepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. í•™ìŠµ loss plot & ì¶”ë¡  ê²°ê³¼ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePx2vCELVnuS"
      },
      "outputs": [],
      "source": [
        "# loss, accuracy, f1 plot ì‹œê°í™” & wandb ì €ì¥\n",
        "trainer.plot_loss(\n",
        "    show=True,\n",
        "    savewandb=True,\n",
        "    savedir=None # ì €ì¥ ì•ˆ í•¨\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9yMO8s6GqAwZ",
        "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
      },
      "outputs": [],
      "source": [
        "display(pred_df[pred_df['ID']=='0a4f2decf34d3bff.jpg'])\n",
        "display(pred_df[pred_df['ID']=='0a12d28777501f71.jpg'])\n",
        "display(pred_df[pred_df['ID']=='0b60e9d39b43e0b9.jpg'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. WandB Finish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# train í´ë”ì— ì €ì¥ëœ ì¦ê°• ì´ë¯¸ì§€ ì‚­ì œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = os.path.join(project_root, 'data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_dir = f'{data_dir}/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for filename in os.listdir(target_dir):\n",
        "    if filename.startswith(\"aug_\"):\n",
        "        file_path = os.path.join(target_dir, filename)\n",
        "        try:\n",
        "            os.remove(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete {file_path}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
