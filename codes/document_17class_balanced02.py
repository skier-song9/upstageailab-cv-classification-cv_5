"""
17í´ë˜ìŠ¤ ë¬¸ì„œ ë¶„ë¥˜ - ê· í˜•ì¡íŒ ë²„ì „
gemini_main_v2_1.py ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ì˜í•œ ê°œì„ ëœ ì½”ë“œ

ì£¼ìš” ê°œì„ ì‚¬í•­:
1. gemini ìŠ¤íƒ€ì¼ ë°ì´í„° ì¦ê°• (morphological, affine ì¤‘ì‹¬)
2. ë‹¨ìˆœí™”ëœ ëª¨ë¸ êµ¬ì¡° (TIMM ë˜í¼ ê¸°ë°˜)
3. ê· í˜•ì¡íŒ í´ë˜ìŠ¤ ì²˜ë¦¬ (ì˜ë£Œë¬¸ì„œ í¸í–¥ ì œê±°)
4. ë²”ìš© ì •ê·œí™” (0.5, 0.5, 0.5)
5. ë¹„ë¬¸ì„œ í´ë˜ìŠ¤ íŠ¹í™” ì²˜ë¦¬
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
import timm
import pandas as pd
import numpy as np
from PIL import Image
import cv2
import albumentations as A
from albumentations.pytorch import ToTensorV2
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
from tqdm import tqdm
import argparse
from types import SimpleNamespace
from datetime import datetime
from zoneinfo import ZoneInfo
import warnings
import random
import math
from torch.optim.lr_scheduler import _LRScheduler
warnings.filterwarnings('ignore')

class CosineAnnealingWarmupRestarts(_LRScheduler):
    # ref : https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup/blob/master/cosine_annealing_warmup/scheduler.py
    def __init__(self, optimizer, first_cycle_steps, cycle_mult=1.0, max_lr=0.1, min_lr=0.001, warmup_steps=0, gamma=1.0, last_epoch=-1):
        assert warmup_steps < first_cycle_steps
        
        self.first_cycle_steps = first_cycle_steps # first cycle step size
        self.cycle_mult = cycle_mult # cycle steps magnification
        self.base_max_lr = max_lr # first max learning rate
        self.max_lr = max_lr # max learning rate in the current cycle
        self.min_lr = min_lr # min learning rate
        self.warmup_steps = warmup_steps # warmup step size
        self.gamma = gamma # decrease rate of max learning rate by cycle
        
        self.cur_cycle_steps = first_cycle_steps # first cycle step size
        self.cycle = 0 # cycle count
        self.step_in_cycle = last_epoch # step size of the current cycle
        
        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)
        
        # set learning rate min_lr
        self.init_lr()
    
    def init_lr(self):
        self.base_lrs = []
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = self.min_lr
            self.base_lrs.append(self.min_lr)
    
    def get_lr(self):
        if self.step_in_cycle == -1: # ì´ˆê¸° ìƒíƒœ
            return self.base_lrs
        elif self.step_in_cycle < self.warmup_steps:
            # ì›œì—… ë‹¨ê³„: í•™ìŠµë¥ ì´ min_lrì—ì„œ max_lrë¡œ ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€í•©ë‹ˆë‹¤.
            return [(self.max_lr - base_lr) * self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]
        else:
            # ì½”ì‚¬ì¸ ì–´ë‹ë§ ë‹¨ê³„: í•™ìŠµë¥ ì´ max_lrì—ì„œ min_lrë¡œ ì½”ì‚¬ì¸ í•¨ìˆ˜ í˜•íƒœë¡œ ê°ì†Œí•©ë‹ˆë‹¤.
            return [base_lr + (self.max_lr - base_lr) * \
                    (1 + math.cos(math.pi * (self.step_in_cycle - self.warmup_steps) / \
                                  (self.cur_cycle_steps - self.warmup_steps))) / 2 
                    for base_lr in self.base_lrs]
        
    def step(self, epoch=None):
        if epoch is None:
            epoch = self.last_epoch + 1
            self.step_in_cycle = self.step_in_cycle + 1
            if self.step_in_cycle >= self.cur_cycle_steps:
                self.cycle += 1
                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps
                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps
        else:
            if epoch >= self.first_cycle_steps:
                if self.cycle_mult == 1.:
                    self.step_in_cycle = epoch % self.first_cycle_steps
                    self.cycle = epoch // self.first_cycle_steps
                else:
                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))
                    self.cycle = n
                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))
                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)
            else:
                self.cur_cycle_steps = self.first_cycle_steps
                self.step_in_cycle = epoch
                
        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)
        self.last_epoch = math.floor(epoch)
        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):
            param_group['lr'] = lr

# Mixupê³¼ Cutmix êµ¬í˜„
def mixup_data(x, y, alpha=0.2):
    """Mixup ë°ì´í„° ì¦ê°•"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    
    batch_size = x.size(0)
    index = torch.randperm(batch_size).to(x.device)
    
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def mixup_criterion(criterion, pred, y_a, y_b, lam):
    """Mixup ì†ì‹¤ í•¨ìˆ˜"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

def cutmix_data(x, y, alpha=1.0):
    """Cutmix ë°ì´í„° ì¦ê°•"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    
    batch_size = x.size(0)
    index = torch.randperm(batch_size).to(x.device)
    
    # ì´ë¯¸ì§€ í¬ê¸°
    _, _, H, W = x.shape
    
    # ë§ˆìŠ¤í¬ ì˜ì—­ ê³„ì‚°
    cut_ratio = np.sqrt(1. - lam)
    cut_w = int(W * cut_ratio)
    cut_h = int(H * cut_ratio)
    
    # ì¤‘ì‹¬ì  ëœë¤ ì„ íƒ
    cx = np.random.randint(W)
    cy = np.random.randint(H)
    
    # ê²½ê³„ ê³„ì‚°
    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)
    
    # ì‹¤ì œ lambda ê°’ ì¡°ì •
    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))
    
    # Cutmix ì ìš©
    mixed_x = x.clone()
    mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]
    
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

# gemini ìŠ¤íƒ€ì¼ Morphological ì—°ì‚°
class Morphological(A.ImageOnlyTransform):
    def __init__(self, scale=(1, 3), operation="dilation", always_apply=False, p=0.5):
        super().__init__(always_apply, p)
        self.scale = scale
        self.operation = operation

    def apply(self, img, **params):
        k = np.random.randint(self.scale[0], self.scale[1] + 1)
        kernel = np.ones((k, k), np.uint8)
        
        if self.operation == "dilation":
            return cv2.dilate(img, kernel, iterations=1)
        elif self.operation == "erosion":
            return cv2.erode(img, kernel, iterations=1)
        else:
            raise ValueError(f"Unsupported operation: {self.operation}")

class BalancedDocumentTransforms:
    """gemini ìŠ¤íƒ€ì¼ ê· í˜•ì¡íŒ ë°ì´í„° ì¦ê°•"""
    
    def __init__(self, image_size=384):
        self.image_size = image_size
    
    def get_gemini_style_augmentation(self):
        """gemini ì½”ë“œ ìŠ¤íƒ€ì¼ ì¦ê°• (EDA ê¸°ë°˜)"""
        return A.Compose([
            # ìƒ‰ìƒ ì¡°ì • (gemini ìŠ¤íƒ€ì¼)
            A.ColorJitter(brightness=0.1, contrast=0.07, saturation=0.07, hue=0.07, p=0.8),
            
            # ê¸°í•˜í•™ì  ë³€í˜• (gemini í•µì‹¬)
            A.Affine(
                scale=(0.85, 1.15),
                translate_percent=(-0.05, 0.05),
                rotate=(-20, 30),
                shear=(-5, 5),
                cval=255,  # í°ìƒ‰ íŒ¨ë”©
                p=0.9
            ),
            
            # ë°˜ì „ ë³€í™˜ (gemini ìŠ¤íƒ€ì¼)
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.5),
            A.Transpose(p=0.5),
            
            # í…ìŠ¤íŠ¸ íŠ¹í™” ì²˜ë¦¬ (ë¹„ë¬¸ì„œ í´ë˜ìŠ¤ë¥¼ ìœ„í•œ í•µì‹¬)
            A.OneOf([
                Morphological(scale=(1, 3), operation="dilation", p=1.0),
                Morphological(scale=(1, 3), operation="erosion", p=1.0),
                A.NoOp(p=1.0),
            ], p=0.4),
            
            # ìµœì†Œí•œì˜ ë¸”ëŸ¬ (gemini ìŠ¤íƒ€ì¼)
            A.OneOf([
                A.GaussianBlur(sigma_limit=(0.5, 2.5), p=1.0),
                A.Blur(blur_limit=(3, 9), p=1.0),
                A.NoOp(p=1.0),
            ], p=0.3),  # í™•ë¥  ëŒ€í­ ê°ì†Œ
            
            # ì•½ê°„ì˜ ë…¸ì´ì¦ˆ (gemini ìŠ¤íƒ€ì¼)
            A.GaussNoise(var_limit=(0.0025, 0.1), p=0.3),  # ê°•ë„ ê°ì†Œ
        ])
    
    def get_medical_document_augmentation(self):
        """ì˜ë£Œë¬¸ì„œ íŠ¹í™” ì¦ê°• (ì§„ë£Œí™•ì¸ì„œ vs ì…í‡´ì›í™•ì¸ì„œ ì˜¤ë¶„ë¥˜ ë°©ì§€)"""
        return A.Compose([
            # ì˜ë£Œë¬¸ì„œ íŠ¹í™” ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ ì‹œë®¬ë ˆì´ì…˜
            A.OneOf([
                # ìˆ˜í‰ ë§ˆìŠ¤í‚¹ (í™˜ì ì •ë³´ ë§ˆìŠ¤í‚¹)
                A.CoarseDropout(
                    max_holes=3, max_height=15, max_width=200,
                    min_holes=1, min_height=10, min_width=100,
                    fill_value=0, p=1.0
                ),
                # ì˜ë£Œê¸°ê´€ëª… ë§ˆìŠ¤í‚¹
                A.CoarseDropout(
                    max_holes=2, max_height=25, max_width=150,
                    min_holes=1, min_height=15, min_width=80,
                    fill_value=0, p=1.0
                ),
                # ë¶€ë¶„ ë§ˆìŠ¤í‚¹ (ì§„ë£Œë‚´ìš© ë“±)
                A.CoarseDropout(
                    max_holes=5, max_height=20, max_width=120,
                    min_holes=2, min_height=10, min_width=60,
                    fill_value=0, p=1.0
                ),
                A.NoOp(p=1.0),
            ], p=0.6),
            
            # ì˜ë£Œë¬¸ì„œ íŠ¹í™” ìŠ¤ìº” í’ˆì§ˆ ì €í•˜ ì‹œë®¬ë ˆì´ì…˜
            A.OneOf([
                A.CLAHE(clip_limit=(2.0, 4.0), p=1.0),  # ëŒ€ë¹„ ê°•í™”
                A.RandomBrightnessContrast(
                    brightness_limit=0.15, contrast_limit=0.15, p=1.0
                ),
                A.NoOp(p=1.0),
            ], p=0.4),
            
            # ì œëª© ì˜ì—­ ë³´ì¡´ì„ ìœ„í•œ ìµœì†Œ ë³€í˜• (ìƒìœ„ 25% ì˜ì—­ ë³´í˜¸)
            A.OneOf([
                A.Affine(
                    translate_percent={'x': (-0.01, 0.01), 'y': (0.0, 0.01)},  # ì„¸ë¡œ ì´ë™ ìµœì†Œí™” (ì œëª© ë³´í˜¸)
                    rotate=(-0.5, 0.5),  # íšŒì „ ê°ë„ ìµœì†Œí™”
                    shear=(-0.5, 0.5),   # ê¸°ìš¸ê¸° ìµœì†Œí™”
                    cval=255,
                    p=1.0
                ),
                A.NoOp(p=1.0),
            ], p=0.5),  # í™•ë¥ ë„ ë‚®ì¶¤
            
            # í…ìŠ¤íŠ¸ íŒ¨í„´ ê°•í™”
            A.OneOf([
                Morphological(scale=(1, 2), operation="dilation", p=1.0),
                Morphological(scale=(1, 2), operation="erosion", p=1.0),
                A.NoOp(p=1.0),
            ], p=0.3),
        ])
    
    def get_rotation_robust_augmentation(self):
        """íšŒì „/ë’¤ì§‘í˜ ê°•ê±´ì„± ì¦ê°• (Test dataset ëŒ€ì‘)"""
        return A.Compose([
            # ë‹¤ì–‘í•œ íšŒì „ ì‹œë®¬ë ˆì´ì…˜ (Test í™˜ê²½)
            A.OneOf([
                A.Rotate(limit=(-180, 180), border_mode=cv2.BORDER_CONSTANT, value=255, p=1.0),
                A.RandomRotate90(p=1.0),
                A.Transpose(p=1.0),
                A.VerticalFlip(p=1.0),
                A.HorizontalFlip(p=1.0),
                A.NoOp(p=1.0),
            ], p=0.4),
            
            # ë…¸ì´ì¦ˆ ì¶”ê°€ (Test dataset íŠ¹ì„±)
            A.OneOf([
                A.GaussNoise(var_limit=(0.001, 0.05), mean=0, p=1.0),
                A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=1.0),
                A.NoOp(p=1.0),
            ], p=0.3),
            
            # ì œëª© ë¶€ë¶„ ì†ì‹¤ ì‹œë®¬ë ˆì´ì…˜ (ì§¤ë¦¼ í˜„ìƒ ëŒ€ì‘)
            A.OneOf([
                A.CoarseDropout(max_holes=2, max_height=30, max_width=100, 
                               min_holes=1, min_height=10, min_width=50, 
                               fill_value=255, p=1.0),
                A.NoOp(p=1.0),
            ], p=0.2),
        ])

    def get_train_transform(self):
        """í›ˆë ¨ìš© ë³€í™˜ (ì œëª© ì˜ì—­ ë³´ì¡´ + Test í™˜ê²½ ëŒ€ì‘)"""
        return A.Compose([
            # 1ë‹¨ê³„: í¬ê¸° ì¡°ì • (ì œëª© ì˜ì—­ ìœ„ì¹˜ í™•ì •)
            A.LongestMaxSize(max_size=self.image_size),
            A.PadIfNeeded(min_height=self.image_size, min_width=self.image_size, 
                         border_mode=cv2.BORDER_CONSTANT, value=255, p=1.0),
            
            # 2ë‹¨ê³„: ë‹¤ì–‘í•œ ì¦ê°• ì „ëµ ì ìš©
            A.OneOf([
                # ì˜ë£Œë¬¸ì„œ íŠ¹í™” ì¦ê°• (ì œëª© ì˜ì—­ ìµœì†Œ ë³€í˜•)
                self.get_medical_document_augmentation(),
                # gemini ìŠ¤íƒ€ì¼ ì¦ê°• (ì¼ë°˜ì ì¸ ë³€í˜•)
                self.get_gemini_style_augmentation(),
                # íšŒì „ ê°•ê±´ì„± ì¦ê°• (Test í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜)
                self.get_rotation_robust_augmentation(),
                A.NoOp(),
            ], p=0.85),  # 85% í™•ë¥ ë¡œ ì¦ê°• ì ìš©
            
            # 3ë‹¨ê³„: ì •ê·œí™”
            A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
            ToTensorV2()
        ])
    
    def get_val_transform(self):
        """ê²€ì¦ìš© ë³€í™˜"""
        return A.Compose([
            A.LongestMaxSize(max_size=self.image_size),
            A.PadIfNeeded(min_height=self.image_size, min_width=self.image_size, 
                         border_mode=cv2.BORDER_CONSTANT, value=255, p=1.0),
            A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
            ToTensorV2()
        ])

class OutpatientVsDischargeDetector(nn.Module):
    """í†µì› vs í‡´ì› êµ¬ë¶„ íŠ¹í™” ëª¨ë“ˆ"""
    
    def __init__(self, feature_dim):
        super().__init__()
        
        # 1. ë¯¸ì„¸ ë¬¸ì íŒ¨í„´ ê°ì§€ê¸° (í†µì›/í‡´ì› êµ¬ë¶„)
        self.character_pattern_detector = nn.Sequential(
            # ê³ í•´ìƒë„ íŒ¨í„´ ê°ì§€
            nn.Conv2d(feature_dim, 512, 1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            
            # ìˆ˜ì§ ìŠ¤íŠ¸ë¡œí¬ ê°ì§€ (é€š vs é€€ì˜ ì°¨ì´)
            nn.Conv2d(512, 256, (5, 1), padding=(2, 0)),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            
            # ìˆ˜í‰ ìŠ¤íŠ¸ë¡œí¬ ê°ì§€
            nn.Conv2d(256, 128, (1, 5), padding=(0, 2)),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            
            # ì„¸ë°€í•œ íŒ¨í„´ ì¶”ì¶œ
            nn.Conv2d(128, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(64, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Conv2d(32, 1, 1),
            nn.Sigmoid()
        )
        
        # 2. ì (Â·) íŒ¨í„´ ê°ì§€ê¸° (ì…Â·í‡´ì› vs í†µì›í™•ì¸ì„œ êµ¬ë¶„)
        self.dot_pattern_detector = nn.Sequential(
            nn.Conv2d(feature_dim, 256, 1),
            nn.ReLU(),
            # ë§¤ìš° ì‘ì€ ì»¤ë„ë¡œ ì  íŒ¨í„´ ê°ì§€
            nn.Conv2d(256, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 1),
            nn.ReLU(),
            nn.Conv2d(64, 1, 1),
            nn.Sigmoid()
        )
        
        # 3. ë¬¸ì„œ ë ˆì´ì•„ì›ƒ ë³µì¡ë„ ë¶„ì„ê¸°
        self.layout_complexity_analyzer = nn.Sequential(
            # í…Œì´ë¸” ë¼ì¸ ê°ì§€
            nn.Conv2d(feature_dim, 256, 7, padding=3),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            
            # ìˆ˜í‰ ë¼ì¸ ê°•í™” ê°ì§€
            nn.Conv2d(256, 128, (1, 7), padding=(0, 3)),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            
            # ìˆ˜ì§ ë¼ì¸ ê°•í™” ê°ì§€  
            nn.Conv2d(128, 64, (7, 1), padding=(3, 0)),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            
            # ë³µì¡ë„ ì¸¡ì •
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
        # 4. Standard-10-view ì œëª© ì˜ì—­ ì§‘ì¤‘ ëª¨ë“ˆ (íšŒì „ ëŒ€ì‘)
        self.standard_10_view_attention = nn.ModuleDict({
            # ì›ë³¸ ë°©í–¥ (0ë„)
            'view_0': self._create_title_detector(feature_dim, 'horizontal'),
            # 90ë„ íšŒì „ (ì„¸ë¡œ ë°©í–¥)
            'view_90': self._create_title_detector(feature_dim, 'vertical'),
            # 180ë„ íšŒì „ (ë’¤ì§‘íŒ ê°€ë¡œ)
            'view_180': self._create_title_detector(feature_dim, 'horizontal_flipped'),
            # 270ë„ íšŒì „ (ë’¤ì§‘íŒ ì„¸ë¡œ)
            'view_270': self._create_title_detector(feature_dim, 'vertical_flipped'),
            # ëŒ€ê°ì„  ë°©í–¥ë“¤
            'view_45': self._create_title_detector(feature_dim, 'diagonal_1'),
            'view_135': self._create_title_detector(feature_dim, 'diagonal_2'),
            'view_225': self._create_title_detector(feature_dim, 'diagonal_3'),
            'view_315': self._create_title_detector(feature_dim, 'diagonal_4'),
            # ì•½ê°„ì˜ ê¸°ìš¸ì–´ì§
            'view_tilt_1': self._create_title_detector(feature_dim, 'slight_tilt_1'),
            'view_tilt_2': self._create_title_detector(feature_dim, 'slight_tilt_2'),
        })
        
        # 10-view í†µí•© ì–´í…ì…˜ ìƒì„±ê¸°
        self.view_aggregator = nn.Sequential(
            nn.Conv2d(10, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(64, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Conv2d(32, 1, 1),
            nn.Sigmoid()
        )
        
        # ë°©í–¥ë³„ ê°€ì¤‘ì¹˜ í•™ìŠµ
        self.orientation_weights = nn.Parameter(torch.ones(10) / 10)
    
    def _create_title_detector(self, feature_dim, orientation_type):
        """ë°©í–¥ë³„ ì œëª© ê°ì§€ê¸° ìƒì„±"""
        if orientation_type in ['horizontal', 'horizontal_flipped']:
            # ê°€ë¡œ ë°©í–¥ ì œëª© ê°ì§€ (ì¼ë°˜ì ì¸ ë¬¸ì„œ)
            return nn.Sequential(
                nn.Conv2d(feature_dim, 256, (3, 7), padding=(1, 3)),
                nn.BatchNorm2d(256),
                nn.ReLU(),
                nn.Conv2d(256, 128, (1, 5), padding=(0, 2)),
                nn.BatchNorm2d(128),
                nn.ReLU(),
                nn.Conv2d(128, 1, 1),
                nn.Sigmoid()
            )
        elif orientation_type in ['vertical', 'vertical_flipped']:
            # ì„¸ë¡œ ë°©í–¥ ì œëª© ê°ì§€ (90ë„ íšŒì „)
            return nn.Sequential(
                nn.Conv2d(feature_dim, 256, (7, 3), padding=(3, 1)),
                nn.BatchNorm2d(256),
                nn.ReLU(),
                nn.Conv2d(256, 128, (5, 1), padding=(2, 0)),
                nn.BatchNorm2d(128),
                nn.ReLU(),
                nn.Conv2d(128, 1, 1),
                nn.Sigmoid()
            )
        elif orientation_type.startswith('diagonal'):
            # ëŒ€ê°ì„  ë°©í–¥ ì œëª© ê°ì§€
            return nn.Sequential(
                nn.Conv2d(feature_dim, 256, 5, padding=2),
                nn.BatchNorm2d(256),
                nn.ReLU(),
                nn.Conv2d(256, 128, 3, padding=1),
                nn.BatchNorm2d(128),
                nn.ReLU(),
                nn.Conv2d(128, 1, 1),
                nn.Sigmoid()
            )
        else:  # slight_tilt ë“±
            # ì•½ê°„ ê¸°ìš¸ì–´ì§„ ì œëª© ê°ì§€
            return nn.Sequential(
                nn.Conv2d(feature_dim, 256, 3, padding=1),
                nn.BatchNorm2d(256),
                nn.ReLU(),
                nn.Conv2d(256, 128, 3, padding=1),
                nn.BatchNorm2d(128),
                nn.ReLU(),
                nn.Conv2d(128, 1, 1),
                nn.Sigmoid()
            )
        
    def forward(self, x):
        b, c, h, w = x.shape
        
        # 1. ë¬¸ì íŒ¨í„´ ë¶„ì„
        char_patterns = self.character_pattern_detector(x)
        
        # 2. ì  íŒ¨í„´ ë¶„ì„ (ìƒìœ„ 20% ì˜ì—­ì—ì„œë§Œ)
        title_region = x[:, :, :h//5, :]
        dot_patterns = self.dot_pattern_detector(title_region)
        # ì „ì²´ ì´ë¯¸ì§€ í¬ê¸°ë¡œ íŒ¨ë”©
        dot_patterns = F.pad(dot_patterns, (0, 0, 0, h - h//5), value=0)
        
        # 3. ë ˆì´ì•„ì›ƒ ë³µì¡ë„ ë¶„ì„
        complexity_score = self.layout_complexity_analyzer(x)
        complexity_map = complexity_score.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, h, w)
        
        # 4. Standard-10-view ì œëª© ì˜ì—­ ì–´í…ì…˜ (íšŒì „ ê°•ê±´ì„±)
        view_attentions = []
        
        # ê° ë°©í–¥ë³„ë¡œ ì œëª© ì˜ì—­ ê°ì§€
        for i, (view_name, detector) in enumerate(self.standard_10_view_attention.items()):
            # ìƒìœ„ ì˜ì—­ì—ì„œ ì œëª© ê°ì§€ (ë°©í–¥ì— ë”°ë¼ ë‹¤ë¥¸ ì˜ì—­ ì„¤ì •)
            if 'vertical' in view_name:
                # ì„¸ë¡œ ë°©í–¥: ì¢Œì¸¡ 20% ì˜ì—­
                region = x[:, :, :, :w//5]
                view_attention = detector(region)
                # ì „ì²´ í¬ê¸°ë¡œ íŒ¨ë”©
                view_attention = F.pad(view_attention, (0, w - w//5, 0, 0), value=0)
            elif 'diagonal' in view_name:
                # ëŒ€ê°ì„  ë°©í–¥: ì½”ë„ˆ ì˜ì—­ë“¤
                if view_name == 'view_45':  # ì¢Œìƒë‹¨
                    region = x[:, :, :h//3, :w//3]
                    view_attention = detector(region)
                    view_attention = F.pad(view_attention, (0, w - w//3, 0, h - h//3), value=0)
                elif view_name == 'view_135':  # ìš°ìƒë‹¨
                    region = x[:, :, :h//3, -w//3:]
                    view_attention = detector(region)
                    view_attention = F.pad(view_attention, (w - w//3, 0, 0, h - h//3), value=0)
                elif view_name == 'view_225':  # ì¢Œí•˜ë‹¨
                    region = x[:, :, -h//3:, :w//3]
                    view_attention = detector(region)
                    view_attention = F.pad(view_attention, (0, w - w//3, h - h//3, 0), value=0)
                else:  # view_315: ìš°í•˜ë‹¨
                    region = x[:, :, -h//3:, -w//3:]
                    view_attention = detector(region)
                    view_attention = F.pad(view_attention, (w - w//3, 0, h - h//3, 0), value=0)
            else:
                # ê°€ë¡œ ë°©í–¥ ë° ê¸°íƒ€: ìƒìœ„ 15% ì˜ì—­
                region = x[:, :, :h//7, :]  # ë” ì •í™•í•œ ì œëª© ì˜ì—­
                view_attention = detector(region)
                # ì „ì²´ í¬ê¸°ë¡œ íŒ¨ë”©
                view_attention = F.pad(view_attention, (0, 0, 0, h - h//7), value=0)
            
            view_attentions.append(view_attention)
        
        # 10ê°œ ë·°ë¥¼ í•˜ë‚˜ë¡œ í†µí•©
        stacked_views = torch.cat(view_attentions, dim=1)  # [B, 10, H, W]
        
        # ë°©í–¥ë³„ ê°€ì¤‘ì¹˜ ì ìš©
        weighted_views = stacked_views * self.orientation_weights.view(1, 10, 1, 1)
        
        # í†µí•© ì–´í…ì…˜ ìƒì„±
        title_attention = self.view_aggregator(weighted_views)
        
        # 5. ì¢…í•© íŠ¹ì„± ìƒì„±
        # í†µì› íŒ¨í„´ ê°•í™” (char_patternsê°€ ë†’ìœ¼ë©´ í†µì› ê°€ëŠ¥ì„±)
        outpatient_enhancement = char_patterns * 2.0
        # ì  íŒ¨í„´ ê°•í™” (dot_patternsê°€ ë†’ìœ¼ë©´ ì…í‡´ì› ê°€ëŠ¥ì„±)
        discharge_enhancement = dot_patterns * 3.0
        # ë³µì¡ë„ ê¸°ë°˜ ê°•í™” (ë³µì¡í•˜ë©´ ì§„ë£Œí™•ì¸ì„œ ê°€ëŠ¥ì„±)
        complexity_enhancement = complexity_map * 1.5
        # ì œëª© ì˜ì—­ ê°•í™”
        title_enhancement = title_attention * 2.5
        
        # ìµœì¢… íŠ¹ì„± ë§µ ìƒì„±
        enhanced_features = x * (1.0 + 
                                outpatient_enhancement + 
                                discharge_enhancement + 
                                complexity_enhancement + 
                                title_enhancement)
        
        return enhanced_features, {
            'char_patterns': char_patterns.mean().item(),
            'dot_patterns': dot_patterns.mean().item(), 
            'complexity': complexity_score.mean().item(),
            'title_attention': title_attention.mean().item()
        }

class Class3vs7SpecializedClassifier(nn.Module):
    """í´ë˜ìŠ¤ 3 vs 7 íŠ¹í™” ë¶„ë¥˜ê¸°"""
    
    def __init__(self, feature_dim, num_classes=17):
        super().__init__()
        
        # ì£¼ ë¶„ë¥˜ê¸° (17í´ë˜ìŠ¤)
        self.main_classifier = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(feature_dim, feature_dim),
            nn.ReLU(),
            nn.BatchNorm1d(feature_dim),
            nn.Dropout(0.2),
            nn.Linear(feature_dim, feature_dim//2),
            nn.ReLU(),
            nn.BatchNorm1d(feature_dim//2),
            nn.Dropout(0.1),
            nn.Linear(feature_dim//2, num_classes)
        )
        
        # í´ë˜ìŠ¤ 3 vs 7 ì´ì§„ ë¶„ë¥˜ê¸°
        self.binary_3vs7_classifier = nn.Sequential(
            nn.Dropout(0.2),
            nn.Linear(feature_dim, feature_dim//2),
            nn.ReLU(),
            nn.BatchNorm1d(feature_dim//2),
            nn.Dropout(0.1),
            nn.Linear(feature_dim//2, feature_dim//4),
            nn.ReLU(),
            nn.Linear(feature_dim//4, 2),  # í´ë˜ìŠ¤ 3 vs 7
            nn.Softmax(dim=1)
        )
        
        # í†µì›/í‡´ì› êµ¬ë¶„ ì ìˆ˜
        self.outpatient_vs_discharge_scorer = nn.Sequential(
            nn.Dropout(0.1),
            nn.Linear(feature_dim, feature_dim//4),
            nn.ReLU(),
            nn.Linear(feature_dim//4, feature_dim//8),
            nn.ReLU(),
            nn.Linear(feature_dim//8, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        main_logits = self.main_classifier(x)
        binary_3vs7_probs = self.binary_3vs7_classifier(x)
        outpatient_score = self.outpatient_vs_discharge_scorer(x)
        
        return main_logits, binary_3vs7_probs, outpatient_score

class GeminiStyleModel(nn.Module):
    """í†µì›/í‡´ì› êµ¬ë¶„ íŠ¹í™” ë¬¸ì„œ ë¶„ë¥˜ ëª¨ë¸"""
    
    def __init__(self, model_name='convnext_base.fb_in22k_ft_in1k_384', num_classes=17):
        super().__init__()
        
        # ë°±ë³¸ ëª¨ë¸
        self.backbone = timm.create_model(
            model_name,
            pretrained=True,
            num_classes=0,
            global_pool=''
        )
        
        # í†µì›/í‡´ì› êµ¬ë¶„ ëª¨ë“ˆ
        self.outpatient_detector = OutpatientVsDischargeDetector(self.backbone.num_features)
        
        # ê¸€ë¡œë²Œ í’€ë§
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        
        # íŠ¹í™” ë¶„ë¥˜ê¸°
        self.classifier = Class3vs7SpecializedClassifier(self.backbone.num_features, num_classes)
        
        # í›„ì²˜ë¦¬ ê·œì¹™
        self.post_processing_enabled = True
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self._initialize_weights()
        
    def _initialize_weights(self):
        """ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        for m in self.classifier.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.BatchNorm1d):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
        
    def forward(self, x):
        # ë°±ë³¸ íŠ¹ì„± ì¶”ì¶œ
        features = self.backbone(x)
        
        # í†µì›/í‡´ì› íŒ¨í„´ ë¶„ì„ ë° íŠ¹ì„± ê°•í™”
        enhanced_features, pattern_info = self.outpatient_detector(features)
        
        # ê¸€ë¡œë²Œ í’€ë§
        pooled_features = self.global_pool(enhanced_features)
        pooled_features = pooled_features.flatten(1)
        
        # ë¶„ë¥˜
        main_logits, binary_3vs7_probs, outpatient_score = self.classifier(pooled_features)
        
        # í›„ì²˜ë¦¬ ì ìš© (ì¶”ë¡  ì‹œ)
        if not self.training and self.post_processing_enabled:
            main_logits = self.apply_post_processing(main_logits, binary_3vs7_probs, 
                                                   outpatient_score, pattern_info)
        
        return main_logits, binary_3vs7_probs, outpatient_score, pattern_info
    
    def apply_post_processing(self, main_logits, binary_3vs7_probs, outpatient_score, pattern_info):
        """í´ë˜ìŠ¤ 3 vs 7 í˜¼ë™ í•´ê²° í›„ì²˜ë¦¬"""
        enhanced_logits = main_logits.clone()
        
        # í´ë˜ìŠ¤ 3ê³¼ 7ì˜ í™•ë¥ 
        class_3_prob = torch.softmax(main_logits, dim=1)[:, 3]  # ì…í‡´ì›í™•ì¸ì„œ
        class_7_prob = torch.softmax(main_logits, dim=1)[:, 7]  # ì§„ë£Œí™•ì¸ì„œ
        
        # 3 vs 7 í˜¼ë™ ìƒí™© ê°ì§€
        confusion_mask = (class_3_prob > 0.2) & (class_7_prob > 0.2)
        
        if confusion_mask.any():
            # ì  íŒ¨í„´ì´ ê°•í•˜ë©´ í´ë˜ìŠ¤ 3 (ì…Â·í‡´ì›í™•ì¸ì„œ) ê°•í™”
            dot_pattern_strong = pattern_info['dot_patterns'] > 0.3
            if dot_pattern_strong:
                enhanced_logits[confusion_mask, 3] += 1.0
                enhanced_logits[confusion_mask, 7] -= 0.5
            
            # í†µì› íŒ¨í„´ì´ ê°•í•˜ê³  ë³µì¡ë„ê°€ ë†’ìœ¼ë©´ í´ë˜ìŠ¤ 7 (ì§„ë£Œí™•ì¸ì„œ) ê°•í™”
            outpatient_pattern_strong = pattern_info['char_patterns'] > 0.4
            high_complexity = pattern_info['complexity'] > 0.6
            if outpatient_pattern_strong and high_complexity:
                enhanced_logits[confusion_mask, 7] += 1.2
                enhanced_logits[confusion_mask, 3] -= 0.8
            
            # ì´ì§„ ë¶„ë¥˜ê¸° ê²°ê³¼ ë°˜ì˜
            binary_class7_prob = binary_3vs7_probs[:, 1]  # í´ë˜ìŠ¤ 7 í™•ë¥ 
            high_binary_7_prob = binary_class7_prob > 0.7
            enhanced_logits[confusion_mask & high_binary_7_prob, 7] += 0.8
            enhanced_logits[confusion_mask & high_binary_7_prob, 3] -= 0.6
        
        return enhanced_logits

class BalancedDocumentDataset(Dataset):
    """ê· í˜•ì¡íŒ ë¬¸ì„œ ë°ì´í„°ì…‹"""
    
    def __init__(self, df, image_dir, transform=None, is_test=False):
        self.df = df
        self.image_dir = image_dir
        self.transform = transform
        self.is_test = is_test
        
        # í´ë˜ìŠ¤ëª… ë§¤í•‘
        self.class_names = {
            0: "account_number", 1: "application_for_payment_of_pregnancy_medical_expenses", 
            2: "car_dashboard", 3: "confirmation_of_admission_and_discharge", 4: "diagnosis",
            5: "driver_lisence", 6: "medical_bill_receipts", 7: "medical_outpatient_certificate",
            8: "national_id_card", 9: "passport", 10: "payment_confirmation",
            11: "pharmaceutical_receipt", 12: "prescription", 13: "resume",
            14: "statement_of_opinion", 15: "vehicle_registration_certificate", 16: "vehicle_registration_plate"
        }
    
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        
        # gemini ìŠ¤íƒ€ì¼ ë‹¨ì¼ í´ë” êµ¬ì¡°ì— ë§ì¶° ìˆ˜ì •
        image_path = os.path.join(self.image_dir, row['ID'])
        
        # ì´ë¯¸ì§€ ë¡œë“œ (gemini ìŠ¤íƒ€ì¼)
        try:
            # PILë¡œ ë¡œë“œ í›„ numpy ë°°ì—´ë¡œ ë³€í™˜ (gemini ìŠ¤íƒ€ì¼)
            img = Image.open(image_path)
            if img.mode == 'RGBA':
                img = img.convert('RGB')
            elif img.mode == 'L':  # Grayscale
                img = img.convert('RGB')
            elif img.mode == 'P':  # Palette mode
                img = img.convert('RGB')
            
            img = np.array(img)  # PIL RGBëŠ” ì´ë¯¸ RGB ìˆœì„œ
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {image_path} - {e}")
            img = np.ones((384, 384, 3), dtype=np.uint8) * 255
        
        # ë³€í™˜ ì ìš©
        if self.transform:
            try:
                img = self.transform(image=img)['image']
            except Exception as e:
                print(f"ë³€í™˜ ì˜¤ë¥˜: {e}")
                img = torch.ones(3, 384, 384)
        
        if self.is_test:
            return img, row['ID']
        else:
            return img, row['target']

class BalancedDocumentTrainer:
    """ê· í˜•ì¡íŒ ë¬¸ì„œ ë¶„ë¥˜ í›ˆë ¨ í´ë˜ìŠ¤"""
    
    def __init__(self, model, train_loader, val_loader, cfg):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.cfg = cfg
        self.device = cfg.device
        
        # ê· í˜•ì¡íŒ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ì˜ë£Œë¬¸ì„œ í¸í–¥ ì œê±°)
        self.criterion = nn.CrossEntropyLoss()  # ê¸°ë³¸ ì†ì‹¤í•¨ìˆ˜
        
        # Mixup/Cutmix ì„¤ì •
        self.use_mixup = getattr(cfg, 'use_mixup', True)
        self.use_cutmix = getattr(cfg, 'use_cutmix', True)
        self.mixup_alpha = getattr(cfg, 'mixup_alpha', 0.2)
        self.cutmix_alpha = getattr(cfg, 'cutmix_alpha', 1.0)
        self.mixup_prob = getattr(cfg, 'mixup_prob', 0.5)  # Mixupê³¼ Cutmix ì ìš© í™•ë¥ 
        
        # gemini ìŠ¤íƒ€ì¼ ìµœì í™”ê¸°
        self.optimizer = optim.AdamW(
            model.parameters(),
            lr=cfg.lr,
            weight_decay=cfg.weight_decay,
            betas=(0.9, 0.999)
        )
        
        # gemini ìŠ¤íƒ€ì¼ ìŠ¤ì¼€ì¤„ëŸ¬
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=cfg.epochs,
            eta_min=cfg.lr * 0.01
        )
        
        # ì¡°ê¸° ì¢…ë£Œ
        self.best_val_f1 = 0
        self.patience_counter = 0
        self.best_model_state = None
        
        # Mixed Precision (gemini ìŠ¤íƒ€ì¼)
        self.scaler = torch.cuda.amp.GradScaler() if cfg.mixed_precision else None
    
    def train_epoch(self):
        """í•œ ì—í¬í¬ í›ˆë ¨ (Mixup/Cutmix ì ìš©)"""
        self.model.train()
        total_loss = 0
        all_preds = []
        all_labels = []
        
        pbar = tqdm(self.train_loader, desc="Training")
        for batch_idx, (images, labels) in enumerate(pbar):
            images, labels = images.to(self.device), labels.to(self.device)
            
            self.optimizer.zero_grad()
            
            # Mixup/Cutmix ì ìš© ì—¬ë¶€ ê²°ì •
            use_aug = False
            labels_a, labels_b, lam = None, None, None  # ë³€ìˆ˜ ì´ˆê¸°í™”
            
            if self.use_mixup or self.use_cutmix:
                if np.random.random() < self.mixup_prob:
                    use_aug = True
                    if self.use_mixup and self.use_cutmix:
                        # 50% í™•ë¥ ë¡œ Mixup ë˜ëŠ” Cutmix ì„ íƒ
                        if np.random.random() < 0.5:
                            images, labels_a, labels_b, lam = mixup_data(images, labels, self.mixup_alpha)
                            aug_type = 'mixup'
                        else:
                            images, labels_a, labels_b, lam = cutmix_data(images, labels, self.cutmix_alpha)
                            aug_type = 'cutmix'
                    elif self.use_mixup:
                        images, labels_a, labels_b, lam = mixup_data(images, labels, self.mixup_alpha)
                        aug_type = 'mixup'
                    else:
                        images, labels_a, labels_b, lam = cutmix_data(images, labels, self.cutmix_alpha)
                        aug_type = 'cutmix'
            
            # Mixed Precision (gemini ìŠ¤íƒ€ì¼)
            if self.scaler:
                with torch.cuda.amp.autocast():
                    model_outputs = self.model(images)
                    main_logits = model_outputs[0]  # ì£¼ ë¶„ë¥˜ê¸° ì¶œë ¥
                    binary_3vs7_probs = model_outputs[1]  # ì´ì§„ ë¶„ë¥˜ê¸° ì¶œë ¥
                    outpatient_score = model_outputs[2]  # í†µì›/í‡´ì› ì ìˆ˜
                    
                    # ì£¼ ì†ì‹¤ ê³„ì‚°
                    if use_aug:
                        main_loss = mixup_criterion(self.criterion, main_logits, labels_a, labels_b, lam)
                    else:
                        main_loss = self.criterion(main_logits, labels)
                    
                    # ë³´ì¡° ì†ì‹¤ (í´ë˜ìŠ¤ 3 vs 7 íŠ¹í™”)
                    binary_labels = torch.zeros_like(labels)
                    binary_labels[labels == 7] = 1  # í´ë˜ìŠ¤ 7ì„ 1ë¡œ
                    binary_labels[labels == 3] = 0  # í´ë˜ìŠ¤ 3ì„ 0ìœ¼ë¡œ
                    
                    # í´ë˜ìŠ¤ 3, 7ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œë§Œ ì´ì§„ ë¶„ë¥˜ ì†ì‹¤ ê³„ì‚°
                    class_3_7_mask = (labels == 3) | (labels == 7)
                    if class_3_7_mask.sum() > 0:
                        if use_aug:
                            # Mixup ì ìš© ì‹œ ì–‘ìª½ ë ˆì´ë¸” ëª¨ë‘ ê³ ë ¤
                            binary_loss_a = F.cross_entropy(binary_3vs7_probs[class_3_7_mask], binary_labels[class_3_7_mask])
                            binary_labels_b = torch.zeros_like(labels_b)
                            binary_labels_b[labels_b == 7] = 1
                            binary_labels_b[labels_b == 3] = 0
                            class_3_7_mask_b = (labels_b == 3) | (labels_b == 7)
                            if class_3_7_mask_b.sum() > 0:
                                binary_loss_b = F.cross_entropy(binary_3vs7_probs[class_3_7_mask_b], binary_labels_b[class_3_7_mask_b])
                                binary_loss = lam * binary_loss_a + (1 - lam) * binary_loss_b
                            else:
                                binary_loss = binary_loss_a
                        else:
                            binary_loss = F.cross_entropy(binary_3vs7_probs[class_3_7_mask], binary_labels[class_3_7_mask])
                    else:
                        binary_loss = torch.tensor(0.0, device=self.device)
                    
                    # ì´ ì†ì‹¤
                    loss = main_loss + 0.3 * binary_loss
                
                self.scaler.scale(loss).backward()
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                model_outputs = self.model(images)
                main_logits = model_outputs[0]
                
                if use_aug:
                    loss = mixup_criterion(self.criterion, main_logits, labels_a, labels_b, lam)
                else:
                    loss = self.criterion(main_logits, labels)
                loss.backward()
                self.optimizer.step()
            
            total_loss += loss.item()
            
            # ì˜ˆì¸¡ ë ˆì´ë¸” ê³„ì‚° (ì£¼ ë¶„ë¥˜ê¸° ì¶œë ¥ ì‚¬ìš©)
            _, predicted = torch.max(main_logits.data, 1)
            all_preds.extend(predicted.cpu().numpy())
            if use_aug:
                # Mixup/Cutmix ì ìš©ì‹œ ë” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ ë ˆì´ë¸” ì‚¬ìš©
                actual_labels = labels_a if lam > 0.5 else labels_b
                all_labels.extend(actual_labels.cpu().numpy())
            else:
                all_labels.extend(labels.cpu().numpy())
            
            pbar.set_postfix({'loss': loss.item()})
            
            # VRAM ìµœì í™” (gemini ìŠ¤íƒ€ì¼)
            del images, main_logits, loss
            if use_aug:
                del labels_a, labels_b
            else:
                del labels
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        avg_loss = total_loss / len(self.train_loader)
        f1 = f1_score(all_labels, all_preds, average='macro')
        
        return avg_loss, f1
    
    def validate(self):
        """ê²€ì¦"""
        self.model.eval()
        total_loss = 0
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for images, labels in tqdm(self.val_loader, desc="Validation"):
                images, labels = images.to(self.device), labels.to(self.device)
                
                if self.scaler:
                    with torch.cuda.amp.autocast():
                        model_outputs = self.model(images)
                        main_logits = model_outputs[0]
                        loss = self.criterion(main_logits, labels)
                else:
                    model_outputs = self.model(images)
                    main_logits = model_outputs[0]
                    loss = self.criterion(main_logits, labels)
                
                total_loss += loss.item()
                
                _, predicted = torch.max(main_logits.data, 1)
                all_preds.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        avg_loss = total_loss / len(self.val_loader)
        f1 = f1_score(all_labels, all_preds, average='macro')
        accuracy = accuracy_score(all_labels, all_preds)
        
        return avg_loss, f1, accuracy, all_preds, all_labels
    
    def train(self):
        """ì „ì²´ í›ˆë ¨ ê³¼ì •"""
        print(f"ğŸš€ ê· í˜•ì¡íŒ í›ˆë ¨ ì‹œì‘ - {self.cfg.epochs}ì—í¬í¬")
        
        for epoch in range(self.cfg.epochs):
            print(f"\n--- Epoch {epoch+1}/{self.cfg.epochs} ---")
            
            # í›ˆë ¨
            train_loss, train_f1 = self.train_epoch()
            
            # ê²€ì¦
            val_loss, val_f1, val_acc, val_preds, val_labels = self.validate()
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            self.scheduler.step()
            
            print(f"Train - Loss: {train_loss:.4f}, F1: {train_f1:.4f}")
            print(f"Val - Loss: {val_loss:.4f}, F1: {val_f1:.4f}, Acc: {val_acc:.4f}")
            print(f"LR: {self.optimizer.param_groups[0]['lr']:.6f}")
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
            if val_f1 > self.best_val_f1:
                self.best_val_f1 = val_f1
                self.best_model_state = self.model.state_dict().copy()
                self.patience_counter = 0
                print(f"ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: {val_f1:.4f}")
                
                # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„
                if epoch % 10 == 0:
                    self._analyze_class_performance(val_labels, val_preds)
            else:
                self.patience_counter += 1
            
            # ì¡°ê¸° ì¢…ë£Œ
            if self.patience_counter >= self.cfg.patience:
                print(f"ì¡°ê¸° ì¢…ë£Œ: {self.cfg.patience} ì—í¬í¬ ë™ì•ˆ ì„±ëŠ¥ í–¥ìƒ ì—†ìŒ")
                break
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë³µì›
        if self.best_model_state:
            self.model.load_state_dict(self.best_model_state)
            print(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë³µì› (F1: {self.best_val_f1:.4f})")
        
        return self.best_val_f1
    
    def _analyze_class_performance(self, true_labels, pred_labels):
        """í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„"""
        per_class_f1 = f1_score(true_labels, pred_labels, average=None)
        
        # í´ë˜ìŠ¤ 3 vs 7 í˜¼ë™ ë¶„ì„
        print("\nğŸ¥ í´ë˜ìŠ¤ 3 vs 7 í˜¼ë™ ë¶„ì„:")
        class_3_indices = [i for i, label in enumerate(true_labels) if label == 3]
        class_7_indices = [i for i, label in enumerate(true_labels) if label == 7]
        
        if class_3_indices:
            class_3_preds = [pred_labels[i] for i in class_3_indices]
            class_3_to_7_errors = sum(1 for pred in class_3_preds if pred == 7)
            class_3_accuracy = sum(1 for pred in class_3_preds if pred == 3) / len(class_3_preds)
            print(f"  í´ë˜ìŠ¤ 3 (ì…í‡´ì›í™•ì¸ì„œ): ì •í™•ë„ {class_3_accuracy:.3f}")
            print(f"  í´ë˜ìŠ¤ 3â†’7 ì˜¤ë¶„ë¥˜: {class_3_to_7_errors}/{len(class_3_indices)} ({class_3_to_7_errors/len(class_3_indices)*100:.1f}%)")
        
        if class_7_indices:
            class_7_preds = [pred_labels[i] for i in class_7_indices]
            class_7_to_3_errors = sum(1 for pred in class_7_preds if pred == 3)
            class_7_accuracy = sum(1 for pred in class_7_preds if pred == 7) / len(class_7_preds)
            print(f"  í´ë˜ìŠ¤ 7 (ì§„ë£Œí™•ì¸ì„œ): ì •í™•ë„ {class_7_accuracy:.3f}")
            print(f"  í´ë˜ìŠ¤ 7â†’3 ì˜¤ë¶„ë¥˜: {class_7_to_3_errors}/{len(class_7_indices)} ({class_7_to_3_errors/len(class_7_indices)*100:.1f}%)")
        
        # ë¹„ë¬¸ì„œ í´ë˜ìŠ¤ ì„±ëŠ¥ í™•ì¸
        non_document_classes = {
            0: "account_number (ì†ê¸€ì”¨)",
            2: "car_dashboard", 
            5: "driver_lisence",
            8: "national_id_card",
            9: "passport",
            15: "vehicle_registration_certificate",
            16: "vehicle_registration_plate"
        }
        
        print("\nğŸš— ë¹„ë¬¸ì„œ í´ë˜ìŠ¤ ì„±ëŠ¥:")
        for cls_id, cls_name in non_document_classes.items():
            if cls_id < len(per_class_f1):
                print(f"  í´ë˜ìŠ¤ {cls_id:2d} ({cls_name}): F1={per_class_f1[cls_id]:.3f}")

def apply_class3_vs_7_postprocessing(predictions, confidence_scores=None):
    """í´ë˜ìŠ¤ 3 vs 7 í˜¼ë™ í•´ê²° í›„ì²˜ë¦¬
    
    ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ê·œì¹™:
    - "í†µì›" í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œëŠ” í´ë˜ìŠ¤ 7 (ì§„ë£Œí™•ì¸ì„œ)
    - "ì…Â·í‡´ì›" í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œëŠ” í´ë˜ìŠ¤ 3 (ì…í‡´ì›í™•ì¸ì„œ)  
    - í˜¼ë™ ì‹œ ì§„ë£Œí™•ì¸ì„œê°€ ë” ì¼ë°˜ì ì´ë¯€ë¡œ í´ë˜ìŠ¤ 7ë¡œ ë³´ì •
    """
    enhanced_predictions = predictions.copy()
    
    # í›„ì²˜ë¦¬ ì ìš© í†µê³„
    class_3_to_7_changes = 0
    
    # í˜¼ë™ì´ ì˜ˆìƒë˜ëŠ” ê²½ìš°ì˜ í›„ì²˜ë¦¬ ê·œì¹™
    for i, pred in enumerate(predictions):
        if confidence_scores is not None:
            conf = confidence_scores[i]
            
            # ë‚®ì€ ì‹ ë¢°ë„ì˜ í´ë˜ìŠ¤ 3 ì˜ˆì¸¡ì„ í´ë˜ìŠ¤ 7ë¡œ ë³€ê²½
            # ì´ìœ : "í†µì›í™•ì¸ì„œ", "í†µì›ì¹˜ë£Œì„œ" ë“±ì´ í´ë˜ìŠ¤ 3ìœ¼ë¡œ ì˜ëª» ë¶„ë¥˜ë˜ëŠ” ê²½ìš°ê°€ ë§ìŒ
            if pred == 3 and conf < 0.6:  # ì‹ ë¢°ë„ ì„ê³„ê°’ ë‚®ì¶¤
                enhanced_predictions[i] = 7
                class_3_to_7_changes += 1
    
    if class_3_to_7_changes > 0:
        print(f"ğŸ”„ í›„ì²˜ë¦¬ ì ìš©: í´ë˜ìŠ¤ 3â†’7 ë³€ê²½ {class_3_to_7_changes}ê°œ")
    
    return enhanced_predictions

def predict_test(model, test_loader, device):
    """í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ (í›„ì²˜ë¦¬ í¬í•¨)"""
    model.eval()
    
    # BatchNormì„ í‰ê°€ ëª¨ë“œë¡œ ê°•ì œ ì„¤ì • (ë°°ì¹˜ í¬ê¸° 1 ëŒ€ì‘)
    for module in model.modules():
        if isinstance(module, nn.BatchNorm1d) or isinstance(module, nn.BatchNorm2d):
            module.track_running_stats = True
    
    predictions = []
    image_ids = []
    confidence_scores = []
    
    with torch.no_grad():
        for images, ids in tqdm(test_loader, desc="Predicting"):
            images = images.to(device)
            model_outputs = model(images)
            main_logits = model_outputs[0]  # ì£¼ ë¶„ë¥˜ê¸° ì¶œë ¥ë§Œ ì‚¬ìš©
            
            # ì†Œí”„íŠ¸ë§¥ìŠ¤ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
            probs = torch.softmax(main_logits, dim=1)
            max_probs, preds = torch.max(probs, 1)
            
            predictions.extend(preds.cpu().numpy())
            confidence_scores.extend(max_probs.cpu().numpy())
            image_ids.extend(ids)
    
    # í´ë˜ìŠ¤ 3 vs 7 í›„ì²˜ë¦¬ ì ìš©
    enhanced_predictions = apply_class3_vs_7_postprocessing(predictions, confidence_scores)
    
    return enhanced_predictions, image_ids

def main():
    parser = argparse.ArgumentParser(description="17í´ë˜ìŠ¤ ë¬¸ì„œ ë¶„ë¥˜ - ê· í˜•ì¡íŒ ë²„ì „ (Mixup/Cutmix ì ìš©)")
    parser.add_argument('--model', type=str, default='convnext_base.fb_in22k_ft_in1k_384')
    parser.add_argument('--epochs', type=int, default=50)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--lr', type=float, default=1e-4)
    parser.add_argument('--image_size', type=int, default=384)
    parser.add_argument('--patience', type=int, default=10)
    parser.add_argument('--use_mixup', action='store_true', default=True, help='Use Mixup augmentation')
    parser.add_argument('--use_cutmix', action='store_true', default=True, help='Use Cutmix augmentation')
    parser.add_argument('--mixup_alpha', type=float, default=0.2, help='Mixup alpha parameter')
    parser.add_argument('--cutmix_alpha', type=float, default=1.0, help='Cutmix alpha parameter')
    parser.add_argument('--mixup_prob', type=float, default=0.5, help='Probability of applying Mixup/Cutmix')
    args = parser.parse_args()
    
    # ì„¤ì •
    cfg = SimpleNamespace(
        model_name=args.model,
        epochs=args.epochs,
        batch_size=args.batch_size,
        lr=args.lr,
        weight_decay=1e-5,
        image_size=args.image_size,
        patience=args.patience,
        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),
        mixed_precision=True,
        random_seed=256,
        # Mixup/Cutmix ì„¤ì •
        use_mixup=args.use_mixup,
        use_cutmix=args.use_cutmix,
        mixup_alpha=args.mixup_alpha,
        cutmix_alpha=args.cutmix_alpha,
        mixup_prob=args.mixup_prob
    )
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì • (gemini_main_v2_1.pyì™€ ë™ì¼í•œ ë°ì´í„°ì…‹ ì‚¬ìš©)
    data_dir = "/data/ephemeral/home/upstageailab-cv-classification-cv_5/aug_data_500_new1"
    
    print(f"ğŸš€ í†µì›/í‡´ì› êµ¬ë¶„ íŠ¹í™” ë¶„ë¥˜ ì‹œì‘ (OCR ì—†ëŠ” ê³ ê¸‰ íŒ¨í„´ ì¸ì‹)")
    print(f"ğŸ–¥ï¸  Device: {cfg.device}")
    print(f"ğŸ”§ Model: {cfg.model_name}")
    print(f"ğŸ“ Image Size: {cfg.image_size}")
    print(f"ğŸ’¾ Data Dir: {data_dir}")
    print(f"ğŸ¯ Mixup: {cfg.use_mixup} (alpha={cfg.mixup_alpha})")
    print(f"ğŸ¯ Cutmix: {cfg.use_cutmix} (alpha={cfg.cutmix_alpha})")
    print(f"ğŸ¯ Aug Prob: {cfg.mixup_prob}")
    print(f"ğŸ” í†µì›(é€šé™¢) vs í‡´ì›(é€€é™¢) ë¬¸ì íŒ¨í„´ ê°ì§€ í™œì„±í™”")
    print(f"âš« ì (Â·) íŒ¨í„´ ê°ì§€ ì‹œìŠ¤í…œ í™œì„±í™” (ì…Â·í‡´ì›í™•ì¸ì„œ)")
    print(f"ğŸ“Š ë¬¸ì„œ ë ˆì´ì•„ì›ƒ ë³µì¡ë„ ë¶„ì„ í™œì„±í™”")
    print(f"ğŸ“ ì œëª© ì˜ì—­ ì§‘ì¤‘ ì–´í…ì…˜ í™œì„±í™”")
    print(f"ğŸ”„ íšŒì „/ë’¤ì§‘í˜/ë…¸ì´ì¦ˆ ê°•ê±´ì„± ì¦ê°• ì ìš©")
    print(f"ğŸ¯ í´ë˜ìŠ¤ 3 vs 7 íŠ¹í™” ì´ì§„ ë¶„ë¥˜ê¸° í¬í•¨")
    
    # ì‹œë“œ ì„¤ì • (gemini ìŠ¤íƒ€ì¼)
    torch.manual_seed(cfg.random_seed)
    np.random.seed(cfg.random_seed)
    random.seed(cfg.random_seed)
    torch.cuda.manual_seed(cfg.random_seed)
    torch.backends.cudnn.deterministic = True
    
    # ë°ì´í„° ë¡œë“œ
    train_df = pd.read_csv(os.path.join(data_dir, "train.csv"))
    test_df = pd.read_csv(os.path.join(data_dir, "sample_submission.csv"))
    
    train_dir = os.path.join(data_dir, "train")
    test_dir = os.path.join(data_dir, "test")
    
    print(f"ğŸ“Š í›ˆë ¨ ë°ì´í„°: {len(train_df)}ê°œ")
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ê°œ (aug_data_1000_new1 ë°ì´í„°ì…‹)")
    
    # ë°ì´í„° ë¶„í• 
    train_data, val_data = train_test_split(
        train_df, test_size=0.15, random_state=cfg.random_seed,
        stratify=train_df['target']
    )
    
    # gemini ìŠ¤íƒ€ì¼ ë³€í™˜
    transform_manager = BalancedDocumentTransforms(cfg.image_size)
    train_transform = transform_manager.get_train_transform()
    val_transform = transform_manager.get_val_transform()
    
    # ë°ì´í„°ì…‹
    train_dataset = BalancedDocumentDataset(train_data, train_dir, train_transform)
    val_dataset = BalancedDocumentDataset(val_data, train_dir, val_transform)
    
    # ë°ì´í„°ë¡œë” (gemini ìŠ¤íƒ€ì¼) - drop_last=Trueë¡œ ë°°ì¹˜ í¬ê¸° 1 ë°©ì§€
    train_loader = DataLoader(
        train_dataset, batch_size=cfg.batch_size,
        shuffle=True, num_workers=4, pin_memory=True,
        drop_last=True  # ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ 1ê°œ ìƒ˜í”Œì¼ ë•Œ ì œê±°
    )
    val_loader = DataLoader(
        val_dataset, batch_size=cfg.batch_size,
        shuffle=False, num_workers=4, pin_memory=True,
        drop_last=True  # ê²€ì¦ì—ì„œë„ ë§ˆì§€ë§‰ ë°°ì¹˜ ì œê±°
    )
    
    # gemini ìŠ¤íƒ€ì¼ ëª¨ë¸
    model = GeminiStyleModel(cfg.model_name, num_classes=17)
    model.to(cfg.device)
    
    print(f"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}")
    
    # í›ˆë ¨
    trainer = BalancedDocumentTrainer(model, train_loader, val_loader, cfg)
    trainer.train()
    
    # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
    print(f"\nğŸ”® í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡")
    test_dataset = BalancedDocumentDataset(test_df, test_dir, val_transform, is_test=True)
    test_loader = DataLoader(
        test_dataset, batch_size=cfg.batch_size,
        shuffle=False, num_workers=4, pin_memory=True,
        drop_last=False  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ëª¨ë“  ìƒ˜í”Œ ì˜ˆì¸¡ í•„ìš”
    )
    
    predictions, image_ids = predict_test(model, test_loader, cfg.device)
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y%m%d_%H%M%S")
    submissions_dir = os.path.join(data_dir, "submissions")
    output_path = os.path.join(submissions_dir, f"balanced_output_10view_characterspecific_{timestamp}.csv")
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    result_df = pd.DataFrame({
        'ID': image_ids,
        'target': predictions
    })
    
    result_df.to_csv(output_path, index=False)
    
    print(f"\nâœ… ê· í˜•ì¡íŒ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {output_path}")
    print(f"ğŸ“Š ì˜ˆì¸¡ ë¶„í¬:")
    print(result_df['target'].value_counts().sort_index())
    
    # ë¹„ë¬¸ì„œ í´ë˜ìŠ¤ ì˜ˆì¸¡ ë¶„ì„
    non_document_classes = [0, 2, 5, 8, 9, 15, 16]
    non_document_predictions = result_df[result_df['target'].isin(non_document_classes)]
    print(f"\nğŸš— ë¹„ë¬¸ì„œ í´ë˜ìŠ¤ ì˜ˆì¸¡ ìˆ˜: {len(non_document_predictions)}")
    
    print(f"\nğŸ‰ ê· í˜•ì¡íŒ ë¬¸ì„œ ë¶„ë¥˜ ì™„ë£Œ!")

if __name__ == "__main__":
    main()